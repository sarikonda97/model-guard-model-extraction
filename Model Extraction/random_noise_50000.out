/var/spool/slurmd/job20950014/slurm_script: line 9: â€‹: command not found

Due to MODULEPATH changes, the following have been reloaded:
  1) libfabric/1.10.1     2) openmpi/4.0.3     3) ucx/1.8.0

=> found transfer set with 10000 samples, 10 classes
Files already downloaded and verified

=> Training at budget = 10000
{'model_dir': 'models/adversary/cifar10-alexnet-adaptive-blur1-10000', 'model_arch': 'resnet34', 'testdataset': 'CIFAR10', 'budgets': '10000', 'device_id': 0, 'batch_size': 64, 'epochs': 50, 'lr': 0.01, 'momentum': 0.5, 'log_interval': 100, 'resume': None, 'lr_step': 60, 'lr_gamma': 0.1, 'num_workers': 10, 'pretrained': 'imagenet', 'img_obfs_tcq': 'blur', 'img_obfs_mag': 1.0, 'weighted_loss': False, 'argmaxed': False, 'optimizer_choice': 'sgdm'}
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[Train] Epoch: 0.64 [6336/10000 (63%)]	Loss: 1.782400	Accuracy: 33.0 (2115/6400)
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[Test]  Epoch: 1	Loss: 0.021989	Acc: 48.9% (4887/10000)
[Train] Epoch: 1.64 [6336/10000 (63%)]	Loss: 1.629993	Accuracy: 48.3 (3092/6400)
[Test]  Epoch: 2	Loss: 0.019860	Acc: 54.5% (5450/10000)
[Train] Epoch: 2.64 [6336/10000 (63%)]	Loss: 1.378082	Accuracy: 55.5 (3549/6400)
[Test]  Epoch: 3	Loss: 0.018776	Acc: 56.6% (5656/10000)
[Train] Epoch: 3.64 [6336/10000 (63%)]	Loss: 1.448867	Accuracy: 62.8 (4018/6400)
[Test]  Epoch: 4	Loss: 0.018628	Acc: 56.1% (5613/10000)
[Train] Epoch: 4.64 [6336/10000 (63%)]	Loss: 1.426578	Accuracy: 68.6 (4391/6400)
[Test]  Epoch: 5	Loss: 0.018492	Acc: 57.2% (5717/10000)
[Train] Epoch: 5.64 [6336/10000 (63%)]	Loss: 1.202763	Accuracy: 72.6 (4645/6400)
[Test]  Epoch: 6	Loss: 0.019168	Acc: 55.5% (5549/10000)
[Train] Epoch: 6.64 [6336/10000 (63%)]	Loss: 1.161443	Accuracy: 75.8 (4853/6400)
[Test]  Epoch: 7	Loss: 0.017644	Acc: 59.0% (5899/10000)
[Train] Epoch: 7.64 [6336/10000 (63%)]	Loss: 1.113700	Accuracy: 78.6 (5033/6400)
[Test]  Epoch: 8	Loss: 0.017926	Acc: 58.3% (5834/10000)
[Train] Epoch: 8.64 [6336/10000 (63%)]	Loss: 1.219721	Accuracy: 80.9 (5177/6400)
[Test]  Epoch: 9	Loss: 0.018405	Acc: 57.5% (5749/10000)
[Train] Epoch: 9.64 [6336/10000 (63%)]	Loss: 1.121367	Accuracy: 81.5 (5219/6400)
[Test]  Epoch: 10	Loss: 0.017534	Acc: 59.2% (5921/10000)
[Train] Epoch: 10.64 [6336/10000 (63%)]	Loss: 1.163150	Accuracy: 83.3 (5330/6400)
[Test]  Epoch: 11	Loss: 0.017562	Acc: 59.4% (5936/10000)
[Train] Epoch: 11.64 [6336/10000 (63%)]	Loss: 1.102541	Accuracy: 83.5 (5343/6400)
[Test]  Epoch: 12	Loss: 0.017449	Acc: 59.1% (5914/10000)
[Train] Epoch: 12.64 [6336/10000 (63%)]	Loss: 1.080984	Accuracy: 84.6 (5416/6400)
[Test]  Epoch: 13	Loss: 0.017306	Acc: 60.0% (6001/10000)
[Train] Epoch: 13.64 [6336/10000 (63%)]	Loss: 0.998964	Accuracy: 85.0 (5442/6400)
[Test]  Epoch: 14	Loss: 0.017037	Acc: 60.8% (6076/10000)
[Train] Epoch: 14.64 [6336/10000 (63%)]	Loss: 0.958548	Accuracy: 84.9 (5435/6400)
[Test]  Epoch: 15	Loss: 0.017295	Acc: 59.8% (5984/10000)
[Train] Epoch: 15.64 [6336/10000 (63%)]	Loss: 1.052397	Accuracy: 85.7 (5486/6400)
[Test]  Epoch: 16	Loss: 0.016788	Acc: 61.1% (6112/10000)
[Train] Epoch: 16.64 [6336/10000 (63%)]	Loss: 1.095999	Accuracy: 85.8 (5490/6400)
[Test]  Epoch: 17	Loss: 0.016792	Acc: 61.1% (6111/10000)
[Train] Epoch: 17.64 [6336/10000 (63%)]	Loss: 0.942206	Accuracy: 86.7 (5548/6400)
[Test]  Epoch: 18	Loss: 0.016811	Acc: 61.4% (6140/10000)
[Train] Epoch: 18.64 [6336/10000 (63%)]	Loss: 0.997116	Accuracy: 86.8 (5558/6400)
[Test]  Epoch: 19	Loss: 0.016848	Acc: 61.1% (6111/10000)
[Train] Epoch: 19.64 [6336/10000 (63%)]	Loss: 1.015955	Accuracy: 87.5 (5597/6400)
[Test]  Epoch: 20	Loss: 0.016884	Acc: 60.9% (6089/10000)
[Train] Epoch: 20.64 [6336/10000 (63%)]	Loss: 1.011061	Accuracy: 86.8 (5558/6400)
[Test]  Epoch: 21	Loss: 0.016930	Acc: 60.5% (6052/10000)
[Train] Epoch: 21.64 [6336/10000 (63%)]	Loss: 1.059615	Accuracy: 87.7 (5614/6400)
[Test]  Epoch: 22	Loss: 0.017384	Acc: 58.9% (5892/10000)
[Train] Epoch: 22.64 [6336/10000 (63%)]	Loss: 1.032855	Accuracy: 86.4 (5531/6400)
[Test]  Epoch: 23	Loss: 0.016710	Acc: 60.7% (6071/10000)
[Train] Epoch: 23.64 [6336/10000 (63%)]	Loss: 0.989902	Accuracy: 87.5 (5598/6400)
[Test]  Epoch: 24	Loss: 0.016662	Acc: 61.4% (6141/10000)
[Train] Epoch: 24.64 [6336/10000 (63%)]	Loss: 1.066350	Accuracy: 87.1 (5575/6400)
[Test]  Epoch: 25	Loss: 0.016735	Acc: 61.0% (6099/10000)
[Train] Epoch: 25.64 [6336/10000 (63%)]	Loss: 0.989244	Accuracy: 87.9 (5623/6400)
[Test]  Epoch: 26	Loss: 0.016835	Acc: 60.7% (6070/10000)
[Train] Epoch: 26.64 [6336/10000 (63%)]	Loss: 0.994597	Accuracy: 88.6 (5669/6400)
[Test]  Epoch: 27	Loss: 0.016677	Acc: 61.2% (6122/10000)
[Train] Epoch: 27.64 [6336/10000 (63%)]	Loss: 0.858222	Accuracy: 88.0 (5629/6400)
[Test]  Epoch: 28	Loss: 0.016253	Acc: 62.6% (6257/10000)
[Train] Epoch: 28.64 [6336/10000 (63%)]	Loss: 1.015036	Accuracy: 88.1 (5637/6400)
[Test]  Epoch: 29	Loss: 0.016581	Acc: 60.8% (6081/10000)
[Train] Epoch: 29.64 [6336/10000 (63%)]	Loss: 1.048726	Accuracy: 87.8 (5619/6400)
[Test]  Epoch: 30	Loss: 0.016371	Acc: 62.1% (6210/10000)
[Train] Epoch: 30.64 [6336/10000 (63%)]	Loss: 0.970749	Accuracy: 88.1 (5640/6400)
[Test]  Epoch: 31	Loss: 0.016515	Acc: 61.8% (6179/10000)
[Train] Epoch: 31.64 [6336/10000 (63%)]	Loss: 0.971236	Accuracy: 88.7 (5679/6400)
[Test]  Epoch: 32	Loss: 0.016398	Acc: 62.4% (6240/10000)
[Train] Epoch: 32.64 [6336/10000 (63%)]	Loss: 0.982346	Accuracy: 88.4 (5655/6400)
[Test]  Epoch: 33	Loss: 0.016701	Acc: 60.9% (6087/10000)
[Train] Epoch: 33.64 [6336/10000 (63%)]	Loss: 0.882258	Accuracy: 88.5 (5662/6400)
[Test]  Epoch: 34	Loss: 0.016473	Acc: 62.0% (6195/10000)
[Train] Epoch: 34.64 [6336/10000 (63%)]	Loss: 0.924831	Accuracy: 88.4 (5658/6400)
[Test]  Epoch: 35	Loss: 0.016386	Acc: 62.3% (6231/10000)
[Train] Epoch: 35.64 [6336/10000 (63%)]	Loss: 0.965188	Accuracy: 88.4 (5655/6400)
[Test]  Epoch: 36	Loss: 0.016535	Acc: 61.8% (6175/10000)
[Train] Epoch: 36.64 [6336/10000 (63%)]	Loss: 0.909169	Accuracy: 89.0 (5697/6400)
[Test]  Epoch: 37	Loss: 0.016614	Acc: 61.4% (6136/10000)
[Train] Epoch: 37.64 [6336/10000 (63%)]	Loss: 0.888822	Accuracy: 88.7 (5676/6400)
[Test]  Epoch: 38	Loss: 0.016806	Acc: 60.6% (6061/10000)
[Train] Epoch: 38.64 [6336/10000 (63%)]	Loss: 0.984365	Accuracy: 88.8 (5680/6400)
[Test]  Epoch: 39	Loss: 0.016501	Acc: 61.6% (6165/10000)
[Train] Epoch: 39.64 [6336/10000 (63%)]	Loss: 0.958465	Accuracy: 89.3 (5713/6400)
[Test]  Epoch: 40	Loss: 0.016523	Acc: 61.9% (6185/10000)
[Train] Epoch: 40.64 [6336/10000 (63%)]	Loss: 1.049734	Accuracy: 89.0 (5694/6400)
[Test]  Epoch: 41	Loss: 0.016638	Acc: 61.4% (6137/10000)
[Train] Epoch: 41.64 [6336/10000 (63%)]	Loss: 0.892431	Accuracy: 89.2 (5712/6400)
[Test]  Epoch: 42	Loss: 0.016164	Acc: 62.9% (6291/10000)
[Train] Epoch: 42.64 [6336/10000 (63%)]	Loss: 1.048220	Accuracy: 89.6 (5733/6400)
[Test]  Epoch: 43	Loss: 0.016301	Acc: 62.7% (6270/10000)
[Train] Epoch: 43.64 [6336/10000 (63%)]	Loss: 0.931887	Accuracy: 89.4 (5724/6400)
[Test]  Epoch: 44	Loss: 0.016386	Acc: 62.2% (6218/10000)
[Train] Epoch: 44.64 [6336/10000 (63%)]	Loss: 0.927613	Accuracy: 89.7 (5743/6400)
[Test]  Epoch: 45	Loss: 0.016684	Acc: 60.9% (6091/10000)
[Train] Epoch: 45.64 [6336/10000 (63%)]	Loss: 1.011367	Accuracy: 89.0 (5698/6400)
[Test]  Epoch: 46	Loss: 0.016216	Acc: 62.9% (6288/10000)
[Train] Epoch: 46.64 [6336/10000 (63%)]	Loss: 0.942083	Accuracy: 90.1 (5769/6400)
[Test]  Epoch: 47	Loss: 0.016463	Acc: 61.5% (6153/10000)
[Train] Epoch: 47.64 [6336/10000 (63%)]	Loss: 0.984784	Accuracy: 89.2 (5708/6400)
[Test]  Epoch: 48	Loss: 0.016486	Acc: 62.0% (6195/10000)
[Train] Epoch: 48.64 [6336/10000 (63%)]	Loss: 0.935477	Accuracy: 89.6 (5736/6400)
[Test]  Epoch: 49	Loss: 0.016312	Acc: 62.5% (6250/10000)
[Train] Epoch: 49.64 [6336/10000 (63%)]	Loss: 0.996940	Accuracy: 90.0 (5759/6400)
[Test]  Epoch: 50	Loss: 0.016109	Acc: 62.8% (6281/10000)
=> found transfer set with 10000 samples, 10 classes
Files already downloaded and verified

=> Training at budget = 10000
{'model_dir': 'models/adversary/cifar10-alexnet-adaptive-blur3-10000', 'model_arch': 'resnet34', 'testdataset': 'CIFAR10', 'budgets': '10000', 'device_id': 0, 'batch_size': 64, 'epochs': 50, 'lr': 0.01, 'momentum': 0.5, 'log_interval': 100, 'resume': None, 'lr_step': 60, 'lr_gamma': 0.1, 'num_workers': 10, 'pretrained': 'imagenet', 'img_obfs_tcq': 'blur', 'img_obfs_mag': 3.0, 'weighted_loss': False, 'argmaxed': False, 'optimizer_choice': 'sgdm'}
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[Train] Epoch: 0.64 [6336/10000 (63%)]	Loss: 1.834051	Accuracy: 31.1 (1992/6400)
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[Test]  Epoch: 1	Loss: 0.025131	Acc: 40.9% (4085/10000)
[Train] Epoch: 1.64 [6336/10000 (63%)]	Loss: 1.600081	Accuracy: 45.8 (2928/6400)
[Test]  Epoch: 2	Loss: 0.023568	Acc: 44.4% (4444/10000)
[Train] Epoch: 2.64 [6336/10000 (63%)]	Loss: 1.378743	Accuracy: 55.4 (3547/6400)
[Test]  Epoch: 3	Loss: 0.024933	Acc: 41.3% (4129/10000)
[Train] Epoch: 3.64 [6336/10000 (63%)]	Loss: 1.342192	Accuracy: 61.5 (3936/6400)
[Test]  Epoch: 4	Loss: 0.024363	Acc: 42.4% (4236/10000)
[Train] Epoch: 4.64 [6336/10000 (63%)]	Loss: 1.314920	Accuracy: 67.0 (4287/6400)
[Test]  Epoch: 5	Loss: 0.022890	Acc: 46.0% (4601/10000)
[Train] Epoch: 5.64 [6336/10000 (63%)]	Loss: 1.445615	Accuracy: 73.0 (4675/6400)
[Test]  Epoch: 6	Loss: 0.023507	Acc: 46.1% (4612/10000)
[Train] Epoch: 6.64 [6336/10000 (63%)]	Loss: 1.198754	Accuracy: 75.6 (4837/6400)
[Test]  Epoch: 7	Loss: 0.022582	Acc: 47.7% (4772/10000)
[Train] Epoch: 7.64 [6336/10000 (63%)]	Loss: 1.149678	Accuracy: 78.4 (5015/6400)
[Test]  Epoch: 8	Loss: 0.023237	Acc: 47.3% (4728/10000)
[Train] Epoch: 8.64 [6336/10000 (63%)]	Loss: 1.081337	Accuracy: 79.4 (5082/6400)
[Test]  Epoch: 9	Loss: 0.022524	Acc: 48.0% (4801/10000)
[Train] Epoch: 9.64 [6336/10000 (63%)]	Loss: 1.089292	Accuracy: 81.2 (5197/6400)
[Test]  Epoch: 10	Loss: 0.023490	Acc: 45.6% (4559/10000)
[Train] Epoch: 10.64 [6336/10000 (63%)]	Loss: 1.263758	Accuracy: 83.4 (5338/6400)
[Test]  Epoch: 11	Loss: 0.021889	Acc: 49.8% (4978/10000)
[Train] Epoch: 11.64 [6336/10000 (63%)]	Loss: 1.228897	Accuracy: 83.6 (5348/6400)
[Test]  Epoch: 12	Loss: 0.022477	Acc: 48.5% (4848/10000)
[Train] Epoch: 12.64 [6336/10000 (63%)]	Loss: 0.995218	Accuracy: 84.4 (5400/6400)
[Test]  Epoch: 13	Loss: 0.022232	Acc: 48.8% (4879/10000)
[Train] Epoch: 13.64 [6336/10000 (63%)]	Loss: 1.112510	Accuracy: 84.4 (5402/6400)
[Test]  Epoch: 14	Loss: 0.021541	Acc: 50.6% (5062/10000)
[Train] Epoch: 14.64 [6336/10000 (63%)]	Loss: 1.114178	Accuracy: 84.3 (5395/6400)
[Test]  Epoch: 15	Loss: 0.024153	Acc: 45.2% (4520/10000)
[Train] Epoch: 15.64 [6336/10000 (63%)]	Loss: 1.030639	Accuracy: 84.7 (5420/6400)
[Test]  Epoch: 16	Loss: 0.022437	Acc: 49.1% (4909/10000)
[Train] Epoch: 16.64 [6336/10000 (63%)]	Loss: 1.164066	Accuracy: 85.4 (5465/6400)
[Test]  Epoch: 17	Loss: 0.022597	Acc: 48.1% (4810/10000)
[Train] Epoch: 17.64 [6336/10000 (63%)]	Loss: 1.064484	Accuracy: 85.8 (5488/6400)
[Test]  Epoch: 18	Loss: 0.022774	Acc: 48.3% (4827/10000)
[Train] Epoch: 18.64 [6336/10000 (63%)]	Loss: 0.952255	Accuracy: 86.2 (5518/6400)
[Test]  Epoch: 19	Loss: 0.023485	Acc: 46.5% (4648/10000)
[Train] Epoch: 19.64 [6336/10000 (63%)]	Loss: 1.069738	Accuracy: 86.3 (5521/6400)
[Test]  Epoch: 20	Loss: 0.022689	Acc: 48.0% (4805/10000)
[Train] Epoch: 20.64 [6336/10000 (63%)]	Loss: 1.057735	Accuracy: 86.5 (5536/6400)
[Test]  Epoch: 21	Loss: 0.022584	Acc: 48.2% (4822/10000)
[Train] Epoch: 21.64 [6336/10000 (63%)]	Loss: 0.922885	Accuracy: 86.5 (5535/6400)
[Test]  Epoch: 22	Loss: 0.021565	Acc: 50.5% (5048/10000)
[Train] Epoch: 22.64 [6336/10000 (63%)]	Loss: 0.843738	Accuracy: 87.4 (5593/6400)
[Test]  Epoch: 23	Loss: 0.022579	Acc: 47.6% (4760/10000)
[Train] Epoch: 23.64 [6336/10000 (63%)]	Loss: 1.012270	Accuracy: 86.5 (5537/6400)
[Test]  Epoch: 24	Loss: 0.021653	Acc: 50.2% (5022/10000)
[Train] Epoch: 24.64 [6336/10000 (63%)]	Loss: 0.910660	Accuracy: 87.5 (5597/6400)
[Test]  Epoch: 25	Loss: 0.022226	Acc: 48.3% (4829/10000)
[Train] Epoch: 25.64 [6336/10000 (63%)]	Loss: 0.963115	Accuracy: 87.5 (5597/6400)
[Test]  Epoch: 26	Loss: 0.021706	Acc: 49.5% (4952/10000)
[Train] Epoch: 26.64 [6336/10000 (63%)]	Loss: 0.965219	Accuracy: 87.7 (5615/6400)
[Test]  Epoch: 27	Loss: 0.022465	Acc: 48.4% (4838/10000)
[Train] Epoch: 27.64 [6336/10000 (63%)]	Loss: 0.942286	Accuracy: 87.3 (5586/6400)
[Test]  Epoch: 28	Loss: 0.021818	Acc: 49.7% (4966/10000)
[Train] Epoch: 28.64 [6336/10000 (63%)]	Loss: 0.909001	Accuracy: 87.3 (5588/6400)
[Test]  Epoch: 29	Loss: 0.023875	Acc: 45.1% (4509/10000)
[Train] Epoch: 29.64 [6336/10000 (63%)]	Loss: 0.984655	Accuracy: 87.9 (5624/6400)
[Test]  Epoch: 30	Loss: 0.021545	Acc: 50.5% (5047/10000)
[Train] Epoch: 30.64 [6336/10000 (63%)]	Loss: 0.938424	Accuracy: 87.5 (5599/6400)
[Test]  Epoch: 31	Loss: 0.021591	Acc: 49.8% (4981/10000)
[Train] Epoch: 31.64 [6336/10000 (63%)]	Loss: 0.981225	Accuracy: 88.5 (5666/6400)
[Test]  Epoch: 32	Loss: 0.022586	Acc: 48.0% (4795/10000)
[Train] Epoch: 32.64 [6336/10000 (63%)]	Loss: 0.946666	Accuracy: 87.0 (5569/6400)
[Test]  Epoch: 33	Loss: 0.022560	Acc: 48.0% (4795/10000)
[Train] Epoch: 33.64 [6336/10000 (63%)]	Loss: 1.021552	Accuracy: 88.5 (5662/6400)
[Test]  Epoch: 34	Loss: 0.022062	Acc: 48.9% (4890/10000)
[Train] Epoch: 34.64 [6336/10000 (63%)]	Loss: 0.937207	Accuracy: 88.9 (5692/6400)
[Test]  Epoch: 35	Loss: 0.022039	Acc: 49.4% (4937/10000)
[Train] Epoch: 35.64 [6336/10000 (63%)]	Loss: 0.915330	Accuracy: 88.2 (5647/6400)
[Test]  Epoch: 36	Loss: 0.022234	Acc: 48.0% (4805/10000)
[Train] Epoch: 36.64 [6336/10000 (63%)]	Loss: 0.966764	Accuracy: 89.4 (5720/6400)
[Test]  Epoch: 37	Loss: 0.021592	Acc: 49.9% (4986/10000)
[Train] Epoch: 37.64 [6336/10000 (63%)]	Loss: 0.773342	Accuracy: 89.5 (5730/6400)
[Test]  Epoch: 38	Loss: 0.021412	Acc: 50.9% (5094/10000)
[Train] Epoch: 38.64 [6336/10000 (63%)]	Loss: 0.928898	Accuracy: 88.7 (5678/6400)
[Test]  Epoch: 39	Loss: 0.022487	Acc: 47.5% (4750/10000)
[Train] Epoch: 39.64 [6336/10000 (63%)]	Loss: 0.975388	Accuracy: 89.2 (5710/6400)
[Test]  Epoch: 40	Loss: 0.021757	Acc: 50.0% (5004/10000)
[Train] Epoch: 40.64 [6336/10000 (63%)]	Loss: 1.002051	Accuracy: 88.9 (5687/6400)
[Test]  Epoch: 41	Loss: 0.021325	Acc: 50.9% (5090/10000)
[Train] Epoch: 41.64 [6336/10000 (63%)]	Loss: 1.047285	Accuracy: 89.6 (5732/6400)
[Test]  Epoch: 42	Loss: 0.021104	Acc: 50.7% (5073/10000)
[Train] Epoch: 42.64 [6336/10000 (63%)]	Loss: 0.821550	Accuracy: 89.3 (5714/6400)
[Test]  Epoch: 43	Loss: 0.021508	Acc: 50.2% (5018/10000)
[Train] Epoch: 43.64 [6336/10000 (63%)]	Loss: 0.975910	Accuracy: 89.1 (5701/6400)
[Test]  Epoch: 44	Loss: 0.022248	Acc: 50.5% (5045/10000)
[Train] Epoch: 44.64 [6336/10000 (63%)]	Loss: 1.031348	Accuracy: 88.3 (5651/6400)
[Test]  Epoch: 45	Loss: 0.022081	Acc: 49.2% (4918/10000)
[Train] Epoch: 45.64 [6336/10000 (63%)]	Loss: 0.946471	Accuracy: 88.8 (5683/6400)
[Test]  Epoch: 46	Loss: 0.022326	Acc: 48.8% (4878/10000)
[Train] Epoch: 46.64 [6336/10000 (63%)]	Loss: 0.896199	Accuracy: 89.7 (5738/6400)
[Test]  Epoch: 47	Loss: 0.021780	Acc: 49.4% (4941/10000)
[Train] Epoch: 47.64 [6336/10000 (63%)]	Loss: 0.920163	Accuracy: 89.9 (5752/6400)
[Test]  Epoch: 48	Loss: 0.021798	Acc: 49.8% (4981/10000)
[Train] Epoch: 48.64 [6336/10000 (63%)]	Loss: 1.008356	Accuracy: 89.8 (5750/6400)
[Test]  Epoch: 49	Loss: 0.021329	Acc: 50.9% (5091/10000)
[Train] Epoch: 49.64 [6336/10000 (63%)]	Loss: 0.982050	Accuracy: 89.1 (5704/6400)
[Test]  Epoch: 50	Loss: 0.021633	Acc: 49.7% (4969/10000)
=> found transfer set with 10000 samples, 10 classes
Files already downloaded and verified

=> Training at budget = 10000
{'model_dir': 'models/adversary/cifar10-alexnet-adaptive-blur5-10000', 'model_arch': 'resnet34', 'testdataset': 'CIFAR10', 'budgets': '10000', 'device_id': 0, 'batch_size': 64, 'epochs': 50, 'lr': 0.01, 'momentum': 0.5, 'log_interval': 100, 'resume': None, 'lr_step': 60, 'lr_gamma': 0.1, 'num_workers': 10, 'pretrained': 'imagenet', 'img_obfs_tcq': 'blur', 'img_obfs_mag': 5.0, 'weighted_loss': False, 'argmaxed': False, 'optimizer_choice': 'sgdm'}
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[Train] Epoch: 0.64 [6336/10000 (63%)]	Loss: 1.984570	Accuracy: 30.0 (1917/6400)
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[Test]  Epoch: 1	Loss: 0.028024	Acc: 32.9% (3293/10000)
[Train] Epoch: 1.64 [6336/10000 (63%)]	Loss: 1.663444	Accuracy: 46.1 (2949/6400)
[Test]  Epoch: 2	Loss: 0.025912	Acc: 38.4% (3844/10000)
[Train] Epoch: 2.64 [6336/10000 (63%)]	Loss: 1.672085	Accuracy: 50.4 (3223/6400)
[Test]  Epoch: 3	Loss: 0.027563	Acc: 37.1% (3710/10000)
[Train] Epoch: 3.64 [6336/10000 (63%)]	Loss: 1.389248	Accuracy: 59.4 (3799/6400)
[Test]  Epoch: 4	Loss: 0.025548	Acc: 40.6% (4063/10000)
[Train] Epoch: 4.64 [6336/10000 (63%)]	Loss: 1.446620	Accuracy: 65.3 (4182/6400)
[Test]  Epoch: 5	Loss: 0.025202	Acc: 40.4% (4037/10000)
[Train] Epoch: 5.64 [6336/10000 (63%)]	Loss: 1.217815	Accuracy: 70.5 (4511/6400)
[Test]  Epoch: 6	Loss: 0.025501	Acc: 41.2% (4123/10000)
[Train] Epoch: 6.64 [6336/10000 (63%)]	Loss: 1.245430	Accuracy: 74.7 (4780/6400)
[Test]  Epoch: 7	Loss: 0.025088	Acc: 42.8% (4276/10000)
[Train] Epoch: 7.64 [6336/10000 (63%)]	Loss: 1.125280	Accuracy: 76.6 (4905/6400)
[Test]  Epoch: 8	Loss: 0.025177	Acc: 41.9% (4187/10000)
[Train] Epoch: 8.64 [6336/10000 (63%)]	Loss: 1.164571	Accuracy: 79.0 (5059/6400)
[Test]  Epoch: 9	Loss: 0.025339	Acc: 41.9% (4188/10000)
[Train] Epoch: 9.64 [6336/10000 (63%)]	Loss: 1.174584	Accuracy: 79.7 (5098/6400)
[Test]  Epoch: 10	Loss: 0.025372	Acc: 41.9% (4189/10000)
[Train] Epoch: 10.64 [6336/10000 (63%)]	Loss: 1.180862	Accuracy: 81.3 (5205/6400)
[Test]  Epoch: 11	Loss: 0.025492	Acc: 41.3% (4128/10000)
[Train] Epoch: 11.64 [6336/10000 (63%)]	Loss: 1.053560	Accuracy: 82.5 (5279/6400)
[Test]  Epoch: 12	Loss: 0.025393	Acc: 42.1% (4209/10000)
[Train] Epoch: 12.64 [6336/10000 (63%)]	Loss: 1.226352	Accuracy: 83.0 (5311/6400)
[Test]  Epoch: 13	Loss: 0.024213	Acc: 43.5% (4346/10000)
[Train] Epoch: 13.64 [6336/10000 (63%)]	Loss: 1.086296	Accuracy: 84.2 (5387/6400)
[Test]  Epoch: 14	Loss: 0.024592	Acc: 43.3% (4326/10000)
[Train] Epoch: 14.64 [6336/10000 (63%)]	Loss: 1.153576	Accuracy: 84.3 (5396/6400)
[Test]  Epoch: 15	Loss: 0.024286	Acc: 43.6% (4360/10000)
[Train] Epoch: 15.64 [6336/10000 (63%)]	Loss: 1.074412	Accuracy: 84.2 (5387/6400)
[Test]  Epoch: 16	Loss: 0.024350	Acc: 43.9% (4389/10000)
[Train] Epoch: 16.64 [6336/10000 (63%)]	Loss: 1.124004	Accuracy: 84.5 (5409/6400)
[Test]  Epoch: 17	Loss: 0.024762	Acc: 43.2% (4318/10000)
[Train] Epoch: 17.64 [6336/10000 (63%)]	Loss: 1.064929	Accuracy: 85.5 (5474/6400)
[Test]  Epoch: 18	Loss: 0.024560	Acc: 43.6% (4363/10000)
[Train] Epoch: 18.64 [6336/10000 (63%)]	Loss: 1.154912	Accuracy: 85.7 (5485/6400)
[Test]  Epoch: 19	Loss: 0.024559	Acc: 43.8% (4380/10000)
[Train] Epoch: 19.64 [6336/10000 (63%)]	Loss: 1.164745	Accuracy: 84.9 (5433/6400)
[Test]  Epoch: 20	Loss: 0.023250	Acc: 46.6% (4663/10000)
[Train] Epoch: 20.64 [6336/10000 (63%)]	Loss: 1.111469	Accuracy: 85.0 (5439/6400)
[Test]  Epoch: 21	Loss: 0.023257	Acc: 46.4% (4638/10000)
[Train] Epoch: 21.64 [6336/10000 (63%)]	Loss: 1.148242	Accuracy: 85.0 (5438/6400)
[Test]  Epoch: 22	Loss: 0.023873	Acc: 44.9% (4488/10000)
[Train] Epoch: 22.64 [6336/10000 (63%)]	Loss: 1.073488	Accuracy: 85.5 (5473/6400)
[Test]  Epoch: 23	Loss: 0.023757	Acc: 44.8% (4482/10000)
[Train] Epoch: 23.64 [6336/10000 (63%)]	Loss: 1.153819	Accuracy: 85.9 (5499/6400)
[Test]  Epoch: 24	Loss: 0.023488	Acc: 45.2% (4522/10000)
[Train] Epoch: 24.64 [6336/10000 (63%)]	Loss: 1.036224	Accuracy: 86.7 (5551/6400)
[Test]  Epoch: 25	Loss: 0.023485	Acc: 45.2% (4522/10000)
[Train] Epoch: 25.64 [6336/10000 (63%)]	Loss: 1.134955	Accuracy: 86.8 (5555/6400)
[Test]  Epoch: 26	Loss: 0.024199	Acc: 44.4% (4436/10000)
[Train] Epoch: 26.64 [6336/10000 (63%)]	Loss: 1.215069	Accuracy: 86.9 (5560/6400)
[Test]  Epoch: 27	Loss: 0.023808	Acc: 44.9% (4491/10000)
[Train] Epoch: 27.64 [6336/10000 (63%)]	Loss: 1.113143	Accuracy: 86.2 (5520/6400)
[Test]  Epoch: 28	Loss: 0.023106	Acc: 46.4% (4642/10000)
[Train] Epoch: 28.64 [6336/10000 (63%)]	Loss: 1.167320	Accuracy: 86.8 (5556/6400)
[Test]  Epoch: 29	Loss: 0.024642	Acc: 42.9% (4287/10000)
[Train] Epoch: 29.64 [6336/10000 (63%)]	Loss: 1.036671	Accuracy: 86.9 (5563/6400)
[Test]  Epoch: 30	Loss: 0.023904	Acc: 44.0% (4401/10000)
[Train] Epoch: 30.64 [6336/10000 (63%)]	Loss: 1.041907	Accuracy: 87.5 (5603/6400)
[Test]  Epoch: 31	Loss: 0.023288	Acc: 46.6% (4658/10000)
[Train] Epoch: 31.64 [6336/10000 (63%)]	Loss: 1.053503	Accuracy: 87.0 (5570/6400)
[Test]  Epoch: 32	Loss: 0.023960	Acc: 45.7% (4569/10000)
[Train] Epoch: 32.64 [6336/10000 (63%)]	Loss: 1.011021	Accuracy: 87.6 (5608/6400)
[Test]  Epoch: 33	Loss: 0.023368	Acc: 45.7% (4570/10000)
[Train] Epoch: 33.64 [6336/10000 (63%)]	Loss: 1.059950	Accuracy: 88.1 (5639/6400)
[Test]  Epoch: 34	Loss: 0.023128	Acc: 46.4% (4637/10000)
[Train] Epoch: 34.64 [6336/10000 (63%)]	Loss: 1.093536	Accuracy: 87.6 (5606/6400)
[Test]  Epoch: 35	Loss: 0.023173	Acc: 46.3% (4630/10000)
[Train] Epoch: 35.64 [6336/10000 (63%)]	Loss: 1.053410	Accuracy: 87.3 (5587/6400)
[Test]  Epoch: 36	Loss: 0.023816	Acc: 44.5% (4455/10000)
[Train] Epoch: 36.64 [6336/10000 (63%)]	Loss: 1.043612	Accuracy: 88.2 (5646/6400)
[Test]  Epoch: 37	Loss: 0.023179	Acc: 46.3% (4633/10000)
[Train] Epoch: 37.64 [6336/10000 (63%)]	Loss: 1.105959	Accuracy: 87.9 (5627/6400)
[Test]  Epoch: 38	Loss: 0.023832	Acc: 44.1% (4410/10000)
[Train] Epoch: 38.64 [6336/10000 (63%)]	Loss: 1.039305	Accuracy: 88.2 (5642/6400)
[Test]  Epoch: 39	Loss: 0.023036	Acc: 46.8% (4675/10000)
[Train] Epoch: 39.64 [6336/10000 (63%)]	Loss: 1.119044	Accuracy: 87.5 (5601/6400)
[Test]  Epoch: 40	Loss: 0.024084	Acc: 43.7% (4371/10000)
[Train] Epoch: 40.64 [6336/10000 (63%)]	Loss: 0.977660	Accuracy: 88.2 (5645/6400)
[Test]  Epoch: 41	Loss: 0.023532	Acc: 45.3% (4528/10000)
[Train] Epoch: 41.64 [6336/10000 (63%)]	Loss: 1.105404	Accuracy: 87.5 (5599/6400)
[Test]  Epoch: 42	Loss: 0.025594	Acc: 43.1% (4312/10000)
[Train] Epoch: 42.64 [6336/10000 (63%)]	Loss: 1.069438	Accuracy: 87.7 (5613/6400)
[Test]  Epoch: 43	Loss: 0.023637	Acc: 45.3% (4530/10000)
[Train] Epoch: 43.64 [6336/10000 (63%)]	Loss: 1.200383	Accuracy: 87.8 (5620/6400)
[Test]  Epoch: 44	Loss: 0.023649	Acc: 45.3% (4530/10000)
[Train] Epoch: 44.64 [6336/10000 (63%)]	Loss: 1.061195	Accuracy: 88.2 (5646/6400)
[Test]  Epoch: 45	Loss: 0.023719	Acc: 44.8% (4482/10000)
[Train] Epoch: 45.64 [6336/10000 (63%)]	Loss: 1.143391	Accuracy: 88.6 (5672/6400)
[Test]  Epoch: 46	Loss: 0.023458	Acc: 45.6% (4561/10000)
[Train] Epoch: 46.64 [6336/10000 (63%)]	Loss: 1.055388	Accuracy: 88.3 (5650/6400)
[Test]  Epoch: 47	Loss: 0.024010	Acc: 44.1% (4412/10000)
[Train] Epoch: 47.64 [6336/10000 (63%)]	Loss: 1.009092	Accuracy: 88.3 (5651/6400)
[Test]  Epoch: 48	Loss: 0.023612	Acc: 45.5% (4553/10000)
[Train] Epoch: 48.64 [6336/10000 (63%)]	Loss: 1.013894	Accuracy: 89.0 (5693/6400)
[Test]  Epoch: 49	Loss: 0.023481	Acc: 45.8% (4577/10000)
[Train] Epoch: 49.64 [6336/10000 (63%)]	Loss: 1.022448	Accuracy: 88.2 (5648/6400)
[Test]  Epoch: 50	Loss: 0.024345	Acc: 44.0% (4395/10000)
=> found transfer set with 10000 samples, 10 classes
Files already downloaded and verified

=> Training at budget = 10000
{'model_dir': 'models/adversary/cifar10-alexnet-adaptive-blur7-10000', 'model_arch': 'resnet34', 'testdataset': 'CIFAR10', 'budgets': '10000', 'device_id': 0, 'batch_size': 64, 'epochs': 50, 'lr': 0.01, 'momentum': 0.5, 'log_interval': 100, 'resume': None, 'lr_step': 60, 'lr_gamma': 0.1, 'num_workers': 10, 'pretrained': 'imagenet', 'img_obfs_tcq': 'blur', 'img_obfs_mag': 7.0, 'weighted_loss': False, 'argmaxed': False, 'optimizer_choice': 'sgdm'}
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[Train] Epoch: 0.64 [6336/10000 (63%)]	Loss: 1.835301	Accuracy: 31.1 (1992/6400)
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[Test]  Epoch: 1	Loss: 0.035927	Acc: 28.1% (2806/10000)
[Train] Epoch: 1.64 [6336/10000 (63%)]	Loss: 1.681711	Accuracy: 46.6 (2985/6400)
[Test]  Epoch: 2	Loss: 0.028116	Acc: 32.5% (3253/10000)
[Train] Epoch: 2.64 [6336/10000 (63%)]	Loss: 1.612453	Accuracy: 54.8 (3508/6400)
[Test]  Epoch: 3	Loss: 0.027656	Acc: 36.1% (3609/10000)
[Train] Epoch: 3.64 [6336/10000 (63%)]	Loss: 1.330060	Accuracy: 59.6 (3817/6400)
[Test]  Epoch: 4	Loss: 0.026575	Acc: 38.4% (3838/10000)
[Train] Epoch: 4.64 [6336/10000 (63%)]	Loss: 1.404174	Accuracy: 65.1 (4166/6400)
[Test]  Epoch: 5	Loss: 0.025865	Acc: 40.6% (4061/10000)
[Train] Epoch: 5.64 [6336/10000 (63%)]	Loss: 1.440490	Accuracy: 69.9 (4473/6400)
[Test]  Epoch: 6	Loss: 0.025837	Acc: 40.4% (4042/10000)
[Train] Epoch: 6.64 [6336/10000 (63%)]	Loss: 1.307002	Accuracy: 72.9 (4664/6400)
[Test]  Epoch: 7	Loss: 0.028227	Acc: 37.6% (3765/10000)
[Train] Epoch: 7.64 [6336/10000 (63%)]	Loss: 1.366478	Accuracy: 76.2 (4874/6400)
[Test]  Epoch: 8	Loss: 0.026647	Acc: 39.6% (3965/10000)
[Train] Epoch: 8.64 [6336/10000 (63%)]	Loss: 1.070958	Accuracy: 77.3 (4949/6400)
[Test]  Epoch: 9	Loss: 0.026962	Acc: 39.0% (3903/10000)
[Train] Epoch: 9.64 [6336/10000 (63%)]	Loss: 1.282650	Accuracy: 80.0 (5123/6400)
[Test]  Epoch: 10	Loss: 0.025240	Acc: 42.6% (4259/10000)
[Train] Epoch: 10.64 [6336/10000 (63%)]	Loss: 1.194423	Accuracy: 80.3 (5139/6400)
[Test]  Epoch: 11	Loss: 0.026230	Acc: 40.5% (4050/10000)
[Train] Epoch: 11.64 [6336/10000 (63%)]	Loss: 1.252697	Accuracy: 81.1 (5193/6400)
[Test]  Epoch: 12	Loss: 0.027701	Acc: 36.2% (3621/10000)
[Train] Epoch: 12.64 [6336/10000 (63%)]	Loss: 1.173258	Accuracy: 80.4 (5145/6400)
[Test]  Epoch: 13	Loss: 0.025780	Acc: 40.7% (4071/10000)
[Train] Epoch: 13.64 [6336/10000 (63%)]	Loss: 1.206534	Accuracy: 82.6 (5284/6400)
[Test]  Epoch: 14	Loss: 0.025522	Acc: 41.8% (4183/10000)
[Train] Epoch: 14.64 [6336/10000 (63%)]	Loss: 1.123046	Accuracy: 83.2 (5328/6400)
[Test]  Epoch: 15	Loss: 0.025251	Acc: 42.1% (4212/10000)
[Train] Epoch: 15.64 [6336/10000 (63%)]	Loss: 1.284513	Accuracy: 83.0 (5313/6400)
[Test]  Epoch: 16	Loss: 0.025522	Acc: 41.2% (4124/10000)
[Train] Epoch: 16.64 [6336/10000 (63%)]	Loss: 1.218085	Accuracy: 83.2 (5324/6400)
[Test]  Epoch: 17	Loss: 0.025694	Acc: 41.0% (4100/10000)
[Train] Epoch: 17.64 [6336/10000 (63%)]	Loss: 1.134261	Accuracy: 84.6 (5414/6400)
[Test]  Epoch: 18	Loss: 0.025484	Acc: 41.7% (4168/10000)
[Train] Epoch: 18.64 [6336/10000 (63%)]	Loss: 1.168861	Accuracy: 83.4 (5337/6400)
[Test]  Epoch: 19	Loss: 0.025470	Acc: 42.2% (4221/10000)
[Train] Epoch: 19.64 [6336/10000 (63%)]	Loss: 1.130575	Accuracy: 85.1 (5445/6400)
[Test]  Epoch: 20	Loss: 0.026932	Acc: 39.8% (3980/10000)
[Train] Epoch: 20.64 [6336/10000 (63%)]	Loss: 1.181912	Accuracy: 83.7 (5356/6400)
[Test]  Epoch: 21	Loss: 0.025150	Acc: 42.5% (4249/10000)
[Train] Epoch: 21.64 [6336/10000 (63%)]	Loss: 1.122705	Accuracy: 84.8 (5427/6400)
[Test]  Epoch: 22	Loss: 0.024848	Acc: 43.1% (4307/10000)
[Train] Epoch: 22.64 [6336/10000 (63%)]	Loss: 1.073840	Accuracy: 85.3 (5462/6400)
[Test]  Epoch: 23	Loss: 0.026094	Acc: 40.7% (4074/10000)
[Train] Epoch: 23.64 [6336/10000 (63%)]	Loss: 1.068718	Accuracy: 84.8 (5429/6400)
[Test]  Epoch: 24	Loss: 0.025117	Acc: 42.2% (4218/10000)
[Train] Epoch: 24.64 [6336/10000 (63%)]	Loss: 1.153331	Accuracy: 85.2 (5453/6400)
[Test]  Epoch: 25	Loss: 0.024584	Acc: 43.5% (4345/10000)
[Train] Epoch: 25.64 [6336/10000 (63%)]	Loss: 1.185239	Accuracy: 85.5 (5475/6400)
[Test]  Epoch: 26	Loss: 0.025578	Acc: 41.5% (4155/10000)
[Train] Epoch: 26.64 [6336/10000 (63%)]	Loss: 1.196879	Accuracy: 84.9 (5435/6400)
[Test]  Epoch: 27	Loss: 0.025126	Acc: 42.7% (4273/10000)
[Train] Epoch: 27.64 [6336/10000 (63%)]	Loss: 1.182213	Accuracy: 85.6 (5480/6400)
[Test]  Epoch: 28	Loss: 0.024978	Acc: 42.6% (4262/10000)
[Train] Epoch: 28.64 [6336/10000 (63%)]	Loss: 1.256025	Accuracy: 85.9 (5497/6400)
[Test]  Epoch: 29	Loss: 0.024479	Acc: 43.5% (4348/10000)
[Train] Epoch: 29.64 [6336/10000 (63%)]	Loss: 1.129963	Accuracy: 85.9 (5497/6400)
[Test]  Epoch: 30	Loss: 0.025450	Acc: 42.1% (4214/10000)
[Train] Epoch: 30.64 [6336/10000 (63%)]	Loss: 1.194215	Accuracy: 86.2 (5514/6400)
[Test]  Epoch: 31	Loss: 0.025245	Acc: 42.5% (4245/10000)
[Train] Epoch: 31.64 [6336/10000 (63%)]	Loss: 1.162542	Accuracy: 87.0 (5570/6400)
[Test]  Epoch: 32	Loss: 0.025041	Acc: 42.8% (4276/10000)
[Train] Epoch: 32.64 [6336/10000 (63%)]	Loss: 1.146075	Accuracy: 86.7 (5547/6400)
[Test]  Epoch: 33	Loss: 0.024314	Acc: 44.2% (4420/10000)
[Train] Epoch: 33.64 [6336/10000 (63%)]	Loss: 1.151545	Accuracy: 86.9 (5560/6400)
[Test]  Epoch: 34	Loss: 0.024335	Acc: 44.0% (4397/10000)
[Train] Epoch: 34.64 [6336/10000 (63%)]	Loss: 1.087227	Accuracy: 86.7 (5549/6400)
[Test]  Epoch: 35	Loss: 0.025216	Acc: 42.6% (4256/10000)
[Train] Epoch: 35.64 [6336/10000 (63%)]	Loss: 1.108787	Accuracy: 86.9 (5563/6400)
[Test]  Epoch: 36	Loss: 0.025051	Acc: 42.6% (4262/10000)
[Train] Epoch: 36.64 [6336/10000 (63%)]	Loss: 1.082469	Accuracy: 86.9 (5564/6400)
[Test]  Epoch: 37	Loss: 0.025077	Acc: 42.3% (4227/10000)
[Train] Epoch: 37.64 [6336/10000 (63%)]	Loss: 1.202113	Accuracy: 87.0 (5565/6400)
[Test]  Epoch: 38	Loss: 0.024583	Acc: 44.3% (4426/10000)
[Train] Epoch: 38.64 [6336/10000 (63%)]	Loss: 1.096460	Accuracy: 87.1 (5577/6400)
[Test]  Epoch: 39	Loss: 0.026433	Acc: 40.6% (4061/10000)
[Train] Epoch: 39.64 [6336/10000 (63%)]	Loss: 1.133240	Accuracy: 86.6 (5542/6400)
[Test]  Epoch: 40	Loss: 0.024843	Acc: 43.0% (4296/10000)
[Train] Epoch: 40.64 [6336/10000 (63%)]	Loss: 1.183866	Accuracy: 87.8 (5616/6400)
[Test]  Epoch: 41	Loss: 0.024405	Acc: 43.7% (4368/10000)
[Train] Epoch: 41.64 [6336/10000 (63%)]	Loss: 1.141014	Accuracy: 88.0 (5630/6400)
[Test]  Epoch: 42	Loss: 0.024631	Acc: 43.6% (4358/10000)
[Train] Epoch: 42.64 [6336/10000 (63%)]	Loss: 1.070737	Accuracy: 87.6 (5609/6400)
[Test]  Epoch: 43	Loss: 0.024435	Acc: 43.7% (4372/10000)
[Train] Epoch: 43.64 [6336/10000 (63%)]	Loss: 1.146794	Accuracy: 87.0 (5571/6400)
[Test]  Epoch: 44	Loss: 0.025180	Acc: 42.3% (4229/10000)
[Train] Epoch: 44.64 [6336/10000 (63%)]	Loss: 1.187248	Accuracy: 87.6 (5609/6400)
[Test]  Epoch: 45	Loss: 0.024844	Acc: 42.6% (4257/10000)
[Train] Epoch: 45.64 [6336/10000 (63%)]	Loss: 1.188282	Accuracy: 87.8 (5620/6400)
[Test]  Epoch: 46	Loss: 0.024195	Acc: 44.2% (4424/10000)
[Train] Epoch: 46.64 [6336/10000 (63%)]	Loss: 1.144239	Accuracy: 87.7 (5612/6400)
[Test]  Epoch: 47	Loss: 0.024459	Acc: 43.3% (4331/10000)
[Train] Epoch: 47.64 [6336/10000 (63%)]	Loss: 1.134886	Accuracy: 88.3 (5654/6400)
[Test]  Epoch: 48	Loss: 0.024931	Acc: 42.8% (4280/10000)
[Train] Epoch: 48.64 [6336/10000 (63%)]	Loss: 1.112258	Accuracy: 87.8 (5618/6400)
[Test]  Epoch: 49	Loss: 0.024406	Acc: 43.7% (4372/10000)
[Train] Epoch: 49.64 [6336/10000 (63%)]	Loss: 1.202088	Accuracy: 88.6 (5669/6400)
[Test]  Epoch: 50	Loss: 0.024208	Acc: 44.8% (4478/10000)
=> found transfer set with 10000 samples, 10 classes
Files already downloaded and verified

=> Training at budget = 10000
{'model_dir': 'models/adversary/cifar10-alexnet-adaptive-blur9-10000', 'model_arch': 'resnet34', 'testdataset': 'CIFAR10', 'budgets': '10000', 'device_id': 0, 'batch_size': 64, 'epochs': 50, 'lr': 0.01, 'momentum': 0.5, 'log_interval': 100, 'resume': None, 'lr_step': 60, 'lr_gamma': 0.1, 'num_workers': 10, 'pretrained': 'imagenet', 'img_obfs_tcq': 'blur', 'img_obfs_mag': 9.0, 'weighted_loss': False, 'argmaxed': False, 'optimizer_choice': 'sgdm'}
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[Train] Epoch: 0.64 [6336/10000 (63%)]	Loss: 1.999042	Accuracy: 35.9 (2296/6400)
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[Test]  Epoch: 1	Loss: 0.032153	Acc: 25.2% (2522/10000)
[Train] Epoch: 1.64 [6336/10000 (63%)]	Loss: 1.661764	Accuracy: 52.2 (3343/6400)
[Test]  Epoch: 2	Loss: 0.031707	Acc: 27.2% (2725/10000)
[Train] Epoch: 2.64 [6336/10000 (63%)]	Loss: 1.655972	Accuracy: 58.4 (3736/6400)
[Test]  Epoch: 3	Loss: 0.028874	Acc: 30.8% (3083/10000)
[Train] Epoch: 3.64 [6336/10000 (63%)]	Loss: 1.563294	Accuracy: 63.1 (4036/6400)
[Test]  Epoch: 4	Loss: 0.029341	Acc: 30.9% (3089/10000)
[Train] Epoch: 4.64 [6336/10000 (63%)]	Loss: 1.462140	Accuracy: 67.1 (4297/6400)
[Test]  Epoch: 5	Loss: 0.030977	Acc: 27.9% (2791/10000)
[Train] Epoch: 5.64 [6336/10000 (63%)]	Loss: 1.448464	Accuracy: 71.1 (4549/6400)
[Test]  Epoch: 6	Loss: 0.030173	Acc: 29.6% (2964/10000)
[Train] Epoch: 6.64 [6336/10000 (63%)]	Loss: 1.449049	Accuracy: 73.0 (4671/6400)
[Test]  Epoch: 7	Loss: 0.028516	Acc: 34.6% (3463/10000)
[Train] Epoch: 7.64 [6336/10000 (63%)]	Loss: 1.601575	Accuracy: 75.5 (4835/6400)
[Test]  Epoch: 8	Loss: 0.030609	Acc: 30.1% (3011/10000)
[Train] Epoch: 8.64 [6336/10000 (63%)]	Loss: 1.380438	Accuracy: 77.7 (4973/6400)
[Test]  Epoch: 9	Loss: 0.029383	Acc: 31.0% (3100/10000)
[Train] Epoch: 9.64 [6336/10000 (63%)]	Loss: 1.345988	Accuracy: 77.4 (4954/6400)
[Test]  Epoch: 10	Loss: 0.029298	Acc: 31.4% (3140/10000)
[Train] Epoch: 10.64 [6336/10000 (63%)]	Loss: 1.338580	Accuracy: 79.0 (5058/6400)
[Test]  Epoch: 11	Loss: 0.027831	Acc: 35.0% (3495/10000)
[Train] Epoch: 11.64 [6336/10000 (63%)]	Loss: 1.305473	Accuracy: 80.1 (5127/6400)
[Test]  Epoch: 12	Loss: 0.028536	Acc: 32.7% (3274/10000)
[Train] Epoch: 12.64 [6336/10000 (63%)]	Loss: 1.363295	Accuracy: 80.8 (5173/6400)
[Test]  Epoch: 13	Loss: 0.030370	Acc: 32.8% (3284/10000)
[Train] Epoch: 13.64 [6336/10000 (63%)]	Loss: 1.390257	Accuracy: 81.0 (5182/6400)
[Test]  Epoch: 14	Loss: 0.028103	Acc: 35.9% (3587/10000)
[Train] Epoch: 14.64 [6336/10000 (63%)]	Loss: 1.267698	Accuracy: 81.9 (5239/6400)
[Test]  Epoch: 15	Loss: 0.027683	Acc: 35.0% (3502/10000)
[Train] Epoch: 15.64 [6336/10000 (63%)]	Loss: 1.307893	Accuracy: 82.2 (5263/6400)
[Test]  Epoch: 16	Loss: 0.028085	Acc: 34.8% (3476/10000)
[Train] Epoch: 16.64 [6336/10000 (63%)]	Loss: 1.392512	Accuracy: 82.3 (5265/6400)
[Test]  Epoch: 17	Loss: 0.027008	Acc: 37.0% (3701/10000)
[Train] Epoch: 17.64 [6336/10000 (63%)]	Loss: 1.239000	Accuracy: 83.0 (5313/6400)
[Test]  Epoch: 18	Loss: 0.030765	Acc: 30.6% (3056/10000)
[Train] Epoch: 18.64 [6336/10000 (63%)]	Loss: 1.443077	Accuracy: 83.3 (5334/6400)
[Test]  Epoch: 19	Loss: 0.027299	Acc: 36.1% (3612/10000)
[Train] Epoch: 19.64 [6336/10000 (63%)]	Loss: 1.419867	Accuracy: 83.3 (5333/6400)
[Test]  Epoch: 20	Loss: 0.029293	Acc: 32.5% (3246/10000)
[Train] Epoch: 20.64 [6336/10000 (63%)]	Loss: 1.267551	Accuracy: 83.0 (5315/6400)
[Test]  Epoch: 21	Loss: 0.028071	Acc: 34.9% (3489/10000)
[Train] Epoch: 21.64 [6336/10000 (63%)]	Loss: 1.281618	Accuracy: 83.3 (5329/6400)
[Test]  Epoch: 22	Loss: 0.027335	Acc: 35.7% (3574/10000)
[Train] Epoch: 22.64 [6336/10000 (63%)]	Loss: 1.376440	Accuracy: 83.9 (5372/6400)
[Test]  Epoch: 23	Loss: 0.027397	Acc: 36.3% (3633/10000)
[Train] Epoch: 23.64 [6336/10000 (63%)]	Loss: 1.286777	Accuracy: 84.9 (5434/6400)
[Test]  Epoch: 24	Loss: 0.027065	Acc: 37.2% (3720/10000)
[Train] Epoch: 24.64 [6336/10000 (63%)]	Loss: 1.330761	Accuracy: 85.1 (5444/6400)
[Test]  Epoch: 25	Loss: 0.029020	Acc: 32.3% (3230/10000)
[Train] Epoch: 25.64 [6336/10000 (63%)]	Loss: 1.472988	Accuracy: 84.5 (5409/6400)
[Test]  Epoch: 26	Loss: 0.028246	Acc: 33.3% (3331/10000)
[Train] Epoch: 26.64 [6336/10000 (63%)]	Loss: 1.422967	Accuracy: 84.4 (5404/6400)
[Test]  Epoch: 27	Loss: 0.027423	Acc: 35.9% (3590/10000)
[Train] Epoch: 27.64 [6336/10000 (63%)]	Loss: 1.347886	Accuracy: 85.0 (5439/6400)
[Test]  Epoch: 28	Loss: 0.027526	Acc: 35.4% (3538/10000)
[Train] Epoch: 28.64 [6336/10000 (63%)]	Loss: 1.283162	Accuracy: 84.9 (5431/6400)
[Test]  Epoch: 29	Loss: 0.028279	Acc: 34.7% (3466/10000)
[Train] Epoch: 29.64 [6336/10000 (63%)]	Loss: 1.330951	Accuracy: 85.5 (5474/6400)
[Test]  Epoch: 30	Loss: 0.026974	Acc: 37.4% (3735/10000)
[Train] Epoch: 30.64 [6336/10000 (63%)]	Loss: 1.356109	Accuracy: 86.0 (5504/6400)
[Test]  Epoch: 31	Loss: 0.026643	Acc: 37.9% (3789/10000)
[Train] Epoch: 31.64 [6336/10000 (63%)]	Loss: 1.283769	Accuracy: 84.8 (5428/6400)
[Test]  Epoch: 32	Loss: 0.029131	Acc: 31.6% (3159/10000)
[Train] Epoch: 32.64 [6336/10000 (63%)]	Loss: 1.412599	Accuracy: 85.3 (5457/6400)
[Test]  Epoch: 33	Loss: 0.027728	Acc: 35.3% (3526/10000)
[Train] Epoch: 33.64 [6336/10000 (63%)]	Loss: 1.303213	Accuracy: 85.2 (5453/6400)
[Test]  Epoch: 34	Loss: 0.027838	Acc: 35.2% (3518/10000)
[Train] Epoch: 34.64 [6336/10000 (63%)]	Loss: 1.353106	Accuracy: 85.7 (5485/6400)
[Test]  Epoch: 35	Loss: 0.026101	Acc: 38.5% (3846/10000)
[Train] Epoch: 35.64 [6336/10000 (63%)]	Loss: 1.280990	Accuracy: 85.8 (5493/6400)
[Test]  Epoch: 36	Loss: 0.027447	Acc: 36.1% (3606/10000)
[Train] Epoch: 36.64 [6336/10000 (63%)]	Loss: 1.388189	Accuracy: 85.6 (5480/6400)
[Test]  Epoch: 37	Loss: 0.027186	Acc: 36.5% (3652/10000)
[Train] Epoch: 37.64 [6336/10000 (63%)]	Loss: 1.369141	Accuracy: 85.8 (5490/6400)
[Test]  Epoch: 38	Loss: 0.027895	Acc: 35.2% (3517/10000)
[Train] Epoch: 38.64 [6336/10000 (63%)]	Loss: 1.307264	Accuracy: 85.7 (5483/6400)
[Test]  Epoch: 39	Loss: 0.027746	Acc: 35.0% (3495/10000)
[Train] Epoch: 39.64 [6336/10000 (63%)]	Loss: 1.344946	Accuracy: 86.5 (5537/6400)
[Test]  Epoch: 40	Loss: 0.026352	Acc: 38.1% (3808/10000)
[Train] Epoch: 40.64 [6336/10000 (63%)]	Loss: 1.335440	Accuracy: 86.7 (5546/6400)
[Test]  Epoch: 41	Loss: 0.026491	Acc: 37.9% (3792/10000)
[Train] Epoch: 41.64 [6336/10000 (63%)]	Loss: 1.359077	Accuracy: 86.7 (5550/6400)
[Test]  Epoch: 42	Loss: 0.027700	Acc: 34.6% (3461/10000)
[Train] Epoch: 42.64 [6336/10000 (63%)]	Loss: 1.415965	Accuracy: 87.1 (5572/6400)
[Test]  Epoch: 43	Loss: 0.025625	Acc: 40.2% (4020/10000)
[Train] Epoch: 43.64 [6336/10000 (63%)]	Loss: 1.296322	Accuracy: 86.3 (5522/6400)
[Test]  Epoch: 44	Loss: 0.026174	Acc: 38.0% (3801/10000)
[Train] Epoch: 44.64 [6336/10000 (63%)]	Loss: 1.317224	Accuracy: 87.1 (5573/6400)
[Test]  Epoch: 45	Loss: 0.025652	Acc: 40.0% (3995/10000)
[Train] Epoch: 45.64 [6336/10000 (63%)]	Loss: 1.246509	Accuracy: 87.0 (5571/6400)
[Test]  Epoch: 46	Loss: 0.028237	Acc: 36.2% (3618/10000)
[Train] Epoch: 46.64 [6336/10000 (63%)]	Loss: 1.382204	Accuracy: 87.2 (5581/6400)
[Test]  Epoch: 47	Loss: 0.026047	Acc: 38.8% (3876/10000)
[Train] Epoch: 47.64 [6336/10000 (63%)]	Loss: 1.275719	Accuracy: 87.5 (5599/6400)
[Test]  Epoch: 48	Loss: 0.026233	Acc: 38.5% (3854/10000)
[Train] Epoch: 48.64 [6336/10000 (63%)]	Loss: 1.293210	Accuracy: 86.3 (5524/6400)
[Test]  Epoch: 49	Loss: 0.026503	Acc: 38.0% (3799/10000)
[Train] Epoch: 49.64 [6336/10000 (63%)]	Loss: 1.265559	Accuracy: 87.1 (5576/6400)
[Test]  Epoch: 50	Loss: 0.025944	Acc: 39.1% (3911/10000)
=> found transfer set with 10000 samples, 10 classes
Files already downloaded and verified

=> Training at budget = 10000
{'model_dir': 'models/adversary/cifar10-alexnet-adaptive-noise0.1-10000', 'model_arch': 'resnet34', 'testdataset': 'CIFAR10', 'budgets': '10000', 'device_id': 0, 'batch_size': 64, 'epochs': 50, 'lr': 0.01, 'momentum': 0.5, 'log_interval': 100, 'resume': None, 'lr_step': 60, 'lr_gamma': 0.1, 'num_workers': 10, 'pretrained': 'imagenet', 'img_obfs_tcq': 'noise', 'img_obfs_mag': 0.1, 'weighted_loss': False, 'argmaxed': False, 'optimizer_choice': 'sgdm'}
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[Train] Epoch: 0.64 [6336/10000 (63%)]	Loss: 1.791251	Accuracy: 33.3 (2134/6400)
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[Test]  Epoch: 1	Loss: 0.028897	Acc: 31.6% (3158/10000)
[Train] Epoch: 1.64 [6336/10000 (63%)]	Loss: 1.671141	Accuracy: 48.5 (3103/6400)
[Test]  Epoch: 2	Loss: 0.026586	Acc: 38.2% (3818/10000)
[Train] Epoch: 2.64 [6336/10000 (63%)]	Loss: 1.674007	Accuracy: 55.4 (3547/6400)
[Test]  Epoch: 3	Loss: 0.025668	Acc: 40.1% (4007/10000)
[Train] Epoch: 3.64 [6336/10000 (63%)]	Loss: 1.585894	Accuracy: 61.5 (3933/6400)
[Test]  Epoch: 4	Loss: 0.025511	Acc: 41.2% (4116/10000)
[Train] Epoch: 4.64 [6336/10000 (63%)]	Loss: 1.433704	Accuracy: 65.3 (4179/6400)
[Test]  Epoch: 5	Loss: 0.024730	Acc: 42.7% (4271/10000)
[Train] Epoch: 5.64 [6336/10000 (63%)]	Loss: 1.297677	Accuracy: 70.1 (4488/6400)
[Test]  Epoch: 6	Loss: 0.024270	Acc: 43.5% (4354/10000)
[Train] Epoch: 6.64 [6336/10000 (63%)]	Loss: 1.235865	Accuracy: 73.2 (4686/6400)
[Test]  Epoch: 7	Loss: 0.023872	Acc: 44.7% (4469/10000)
[Train] Epoch: 7.64 [6336/10000 (63%)]	Loss: 1.302644	Accuracy: 74.6 (4775/6400)
[Test]  Epoch: 8	Loss: 0.024384	Acc: 43.8% (4383/10000)
[Train] Epoch: 8.64 [6336/10000 (63%)]	Loss: 1.181933	Accuracy: 76.5 (4897/6400)
[Test]  Epoch: 9	Loss: 0.023577	Acc: 45.7% (4570/10000)
[Train] Epoch: 9.64 [6336/10000 (63%)]	Loss: 1.288415	Accuracy: 77.5 (4958/6400)
[Test]  Epoch: 10	Loss: 0.024061	Acc: 43.8% (4383/10000)
[Train] Epoch: 10.64 [6336/10000 (63%)]	Loss: 1.424448	Accuracy: 79.0 (5059/6400)
[Test]  Epoch: 11	Loss: 0.024220	Acc: 44.0% (4401/10000)
[Train] Epoch: 11.64 [6336/10000 (63%)]	Loss: 1.266537	Accuracy: 79.5 (5091/6400)
[Test]  Epoch: 12	Loss: 0.023916	Acc: 44.4% (4437/10000)
[Train] Epoch: 12.64 [6336/10000 (63%)]	Loss: 1.298208	Accuracy: 81.1 (5189/6400)
[Test]  Epoch: 13	Loss: 0.024045	Acc: 43.6% (4360/10000)
[Train] Epoch: 13.64 [6336/10000 (63%)]	Loss: 1.181193	Accuracy: 82.6 (5289/6400)
[Test]  Epoch: 14	Loss: 0.024386	Acc: 43.3% (4327/10000)
[Train] Epoch: 14.64 [6336/10000 (63%)]	Loss: 1.159583	Accuracy: 81.9 (5244/6400)
[Test]  Epoch: 15	Loss: 0.023731	Acc: 44.5% (4449/10000)
[Train] Epoch: 15.64 [6336/10000 (63%)]	Loss: 1.134047	Accuracy: 83.2 (5323/6400)
[Test]  Epoch: 16	Loss: 0.023703	Acc: 44.8% (4481/10000)
[Train] Epoch: 16.64 [6336/10000 (63%)]	Loss: 1.188533	Accuracy: 82.3 (5270/6400)
[Test]  Epoch: 17	Loss: 0.023501	Acc: 45.3% (4531/10000)
[Train] Epoch: 17.64 [6336/10000 (63%)]	Loss: 1.145421	Accuracy: 84.0 (5379/6400)
[Test]  Epoch: 18	Loss: 0.023901	Acc: 44.0% (4396/10000)
[Train] Epoch: 18.64 [6336/10000 (63%)]	Loss: 1.284420	Accuracy: 83.6 (5353/6400)
[Test]  Epoch: 19	Loss: 0.023935	Acc: 43.7% (4367/10000)
[Train] Epoch: 19.64 [6336/10000 (63%)]	Loss: 1.186307	Accuracy: 83.8 (5361/6400)
[Test]  Epoch: 20	Loss: 0.023702	Acc: 45.1% (4507/10000)
[Train] Epoch: 20.64 [6336/10000 (63%)]	Loss: 1.338089	Accuracy: 84.5 (5411/6400)
[Test]  Epoch: 21	Loss: 0.024037	Acc: 44.0% (4400/10000)
[Train] Epoch: 21.64 [6336/10000 (63%)]	Loss: 1.215468	Accuracy: 84.0 (5373/6400)
[Test]  Epoch: 22	Loss: 0.023335	Acc: 45.9% (4586/10000)
[Train] Epoch: 22.64 [6336/10000 (63%)]	Loss: 1.166137	Accuracy: 84.4 (5401/6400)
[Test]  Epoch: 23	Loss: 0.023773	Acc: 44.6% (4463/10000)
[Train] Epoch: 23.64 [6336/10000 (63%)]	Loss: 1.236603	Accuracy: 85.9 (5499/6400)
[Test]  Epoch: 24	Loss: 0.023548	Acc: 45.2% (4523/10000)
[Train] Epoch: 24.64 [6336/10000 (63%)]	Loss: 1.303141	Accuracy: 85.8 (5490/6400)
[Test]  Epoch: 25	Loss: 0.023076	Acc: 46.3% (4626/10000)
[Train] Epoch: 25.64 [6336/10000 (63%)]	Loss: 1.156396	Accuracy: 85.0 (5441/6400)
[Test]  Epoch: 26	Loss: 0.023642	Acc: 44.7% (4468/10000)
[Train] Epoch: 26.64 [6336/10000 (63%)]	Loss: 1.270666	Accuracy: 85.6 (5478/6400)
[Test]  Epoch: 27	Loss: 0.023464	Acc: 45.2% (4519/10000)
[Train] Epoch: 27.64 [6336/10000 (63%)]	Loss: 1.220589	Accuracy: 85.8 (5489/6400)
[Test]  Epoch: 28	Loss: 0.023826	Acc: 44.4% (4440/10000)
[Train] Epoch: 28.64 [6336/10000 (63%)]	Loss: 1.209958	Accuracy: 85.6 (5477/6400)
[Test]  Epoch: 29	Loss: 0.023466	Acc: 45.4% (4539/10000)
[Train] Epoch: 29.64 [6336/10000 (63%)]	Loss: 1.154403	Accuracy: 86.0 (5502/6400)
[Test]  Epoch: 30	Loss: 0.023569	Acc: 45.2% (4524/10000)
[Train] Epoch: 30.64 [6336/10000 (63%)]	Loss: 1.147635	Accuracy: 86.4 (5531/6400)
[Test]  Epoch: 31	Loss: 0.023284	Acc: 45.5% (4553/10000)
[Train] Epoch: 31.64 [6336/10000 (63%)]	Loss: 1.038916	Accuracy: 86.0 (5504/6400)
[Test]  Epoch: 32	Loss: 0.023483	Acc: 45.8% (4580/10000)
[Train] Epoch: 32.64 [6336/10000 (63%)]	Loss: 1.146950	Accuracy: 86.8 (5554/6400)
[Test]  Epoch: 33	Loss: 0.023663	Acc: 45.0% (4501/10000)
[Train] Epoch: 33.64 [6336/10000 (63%)]	Loss: 1.082005	Accuracy: 86.9 (5559/6400)
[Test]  Epoch: 34	Loss: 0.023186	Acc: 46.3% (4634/10000)
[Train] Epoch: 34.64 [6336/10000 (63%)]	Loss: 1.221940	Accuracy: 87.1 (5575/6400)
[Test]  Epoch: 35	Loss: 0.023573	Acc: 44.5% (4455/10000)
[Train] Epoch: 35.64 [6336/10000 (63%)]	Loss: 1.071256	Accuracy: 87.2 (5580/6400)
[Test]  Epoch: 36	Loss: 0.023825	Acc: 44.2% (4417/10000)
[Train] Epoch: 36.64 [6336/10000 (63%)]	Loss: 1.288768	Accuracy: 87.1 (5576/6400)
[Test]  Epoch: 37	Loss: 0.023170	Acc: 47.0% (4700/10000)
[Train] Epoch: 37.64 [6336/10000 (63%)]	Loss: 1.237351	Accuracy: 88.0 (5630/6400)
[Test]  Epoch: 38	Loss: 0.023798	Acc: 44.8% (4477/10000)
[Train] Epoch: 38.64 [6336/10000 (63%)]	Loss: 1.131877	Accuracy: 86.7 (5550/6400)
[Test]  Epoch: 39	Loss: 0.023221	Acc: 45.7% (4574/10000)
[Train] Epoch: 39.64 [6336/10000 (63%)]	Loss: 1.123783	Accuracy: 88.1 (5638/6400)
[Test]  Epoch: 40	Loss: 0.023410	Acc: 45.6% (4565/10000)
[Train] Epoch: 40.64 [6336/10000 (63%)]	Loss: 1.233830	Accuracy: 87.4 (5594/6400)
[Test]  Epoch: 41	Loss: 0.023131	Acc: 46.6% (4661/10000)
[Train] Epoch: 41.64 [6336/10000 (63%)]	Loss: 1.245140	Accuracy: 87.7 (5613/6400)
[Test]  Epoch: 42	Loss: 0.023340	Acc: 45.3% (4532/10000)
[Train] Epoch: 42.64 [6336/10000 (63%)]	Loss: 1.163502	Accuracy: 87.5 (5603/6400)
[Test]  Epoch: 43	Loss: 0.023620	Acc: 44.5% (4452/10000)
[Train] Epoch: 43.64 [6336/10000 (63%)]	Loss: 1.141741	Accuracy: 87.5 (5602/6400)
[Test]  Epoch: 44	Loss: 0.023446	Acc: 45.4% (4535/10000)
[Train] Epoch: 44.64 [6336/10000 (63%)]	Loss: 1.139506	Accuracy: 87.5 (5602/6400)
[Test]  Epoch: 45	Loss: 0.023604	Acc: 45.2% (4525/10000)
[Train] Epoch: 45.64 [6336/10000 (63%)]	Loss: 1.230176	Accuracy: 87.4 (5593/6400)
[Test]  Epoch: 46	Loss: 0.023322	Acc: 45.5% (4554/10000)
[Train] Epoch: 46.64 [6336/10000 (63%)]	Loss: 1.164755	Accuracy: 88.6 (5673/6400)
[Test]  Epoch: 47	Loss: 0.023421	Acc: 46.0% (4597/10000)
[Train] Epoch: 47.64 [6336/10000 (63%)]	Loss: 1.229417	Accuracy: 87.8 (5620/6400)
[Test]  Epoch: 48	Loss: 0.023504	Acc: 45.1% (4506/10000)
[Train] Epoch: 48.64 [6336/10000 (63%)]	Loss: 1.221716	Accuracy: 86.6 (5544/6400)
[Test]  Epoch: 49	Loss: 0.023148	Acc: 46.4% (4644/10000)
[Train] Epoch: 49.64 [6336/10000 (63%)]	Loss: 1.171473	Accuracy: 88.2 (5645/6400)
[Test]  Epoch: 50	Loss: 0.023561	Acc: 46.0% (4596/10000)
=> found transfer set with 10000 samples, 10 classes
Files already downloaded and verified

=> Training at budget = 10000
{'model_dir': 'models/adversary/cifar10-alexnet-adaptive-noise0.2-10000', 'model_arch': 'resnet34', 'testdataset': 'CIFAR10', 'budgets': '10000', 'device_id': 0, 'batch_size': 64, 'epochs': 50, 'lr': 0.01, 'momentum': 0.5, 'log_interval': 100, 'resume': None, 'lr_step': 60, 'lr_gamma': 0.1, 'num_workers': 10, 'pretrained': 'imagenet', 'img_obfs_tcq': 'noise', 'img_obfs_mag': 0.2, 'weighted_loss': False, 'argmaxed': False, 'optimizer_choice': 'sgdm'}
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[Train] Epoch: 0.64 [6336/10000 (63%)]	Loss: 1.873323	Accuracy: 27.9 (1785/6400)
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[Test]  Epoch: 1	Loss: 0.031733	Acc: 26.1% (2608/10000)
[Train] Epoch: 1.64 [6336/10000 (63%)]	Loss: 1.820518	Accuracy: 42.6 (2727/6400)
[Test]  Epoch: 2	Loss: 0.030374	Acc: 28.2% (2818/10000)
[Train] Epoch: 2.64 [6336/10000 (63%)]	Loss: 1.727067	Accuracy: 49.5 (3171/6400)
[Test]  Epoch: 3	Loss: 0.029482	Acc: 32.1% (3214/10000)
[Train] Epoch: 3.64 [6336/10000 (63%)]	Loss: 1.712383	Accuracy: 54.7 (3501/6400)
[Test]  Epoch: 4	Loss: 0.028333	Acc: 33.5% (3353/10000)
[Train] Epoch: 4.64 [6336/10000 (63%)]	Loss: 1.442272	Accuracy: 59.6 (3812/6400)
[Test]  Epoch: 5	Loss: 0.028578	Acc: 34.1% (3415/10000)
[Train] Epoch: 5.64 [6336/10000 (63%)]	Loss: 1.611730	Accuracy: 64.2 (4112/6400)
[Test]  Epoch: 6	Loss: 0.029463	Acc: 31.4% (3138/10000)
[Train] Epoch: 6.64 [6336/10000 (63%)]	Loss: 1.509940	Accuracy: 66.4 (4252/6400)
[Test]  Epoch: 7	Loss: 0.029614	Acc: 32.5% (3254/10000)
[Train] Epoch: 7.64 [6336/10000 (63%)]	Loss: 1.402785	Accuracy: 69.7 (4460/6400)
[Test]  Epoch: 8	Loss: 0.027938	Acc: 36.5% (3647/10000)
[Train] Epoch: 8.64 [6336/10000 (63%)]	Loss: 1.565773	Accuracy: 71.4 (4568/6400)
[Test]  Epoch: 9	Loss: 0.027447	Acc: 36.8% (3682/10000)
[Train] Epoch: 9.64 [6336/10000 (63%)]	Loss: 1.580950	Accuracy: 73.8 (4726/6400)
[Test]  Epoch: 10	Loss: 0.028610	Acc: 33.9% (3389/10000)
[Train] Epoch: 10.64 [6336/10000 (63%)]	Loss: 1.440404	Accuracy: 75.7 (4846/6400)
[Test]  Epoch: 11	Loss: 0.027815	Acc: 35.4% (3537/10000)
[Train] Epoch: 11.64 [6336/10000 (63%)]	Loss: 1.452185	Accuracy: 75.9 (4857/6400)
[Test]  Epoch: 12	Loss: 0.027726	Acc: 35.8% (3579/10000)
[Train] Epoch: 12.64 [6336/10000 (63%)]	Loss: 1.347464	Accuracy: 76.2 (4874/6400)
[Test]  Epoch: 13	Loss: 0.027769	Acc: 35.5% (3555/10000)
[Train] Epoch: 13.64 [6336/10000 (63%)]	Loss: 1.556345	Accuracy: 77.5 (4962/6400)
[Test]  Epoch: 14	Loss: 0.028335	Acc: 35.0% (3500/10000)
[Train] Epoch: 14.64 [6336/10000 (63%)]	Loss: 1.526660	Accuracy: 78.3 (5011/6400)
[Test]  Epoch: 15	Loss: 0.028515	Acc: 34.8% (3477/10000)
[Train] Epoch: 15.64 [6336/10000 (63%)]	Loss: 1.382355	Accuracy: 79.6 (5093/6400)
[Test]  Epoch: 16	Loss: 0.028235	Acc: 34.5% (3452/10000)
[Train] Epoch: 16.64 [6336/10000 (63%)]	Loss: 1.282829	Accuracy: 81.1 (5191/6400)
[Test]  Epoch: 17	Loss: 0.028679	Acc: 33.4% (3337/10000)
[Train] Epoch: 17.64 [6336/10000 (63%)]	Loss: 1.266988	Accuracy: 80.1 (5124/6400)
[Test]  Epoch: 18	Loss: 0.027891	Acc: 35.9% (3592/10000)
[Train] Epoch: 18.64 [6336/10000 (63%)]	Loss: 1.416735	Accuracy: 81.2 (5197/6400)
[Test]  Epoch: 19	Loss: 0.027700	Acc: 36.6% (3659/10000)
[Train] Epoch: 19.64 [6336/10000 (63%)]	Loss: 1.411036	Accuracy: 81.7 (5230/6400)
[Test]  Epoch: 20	Loss: 0.027379	Acc: 36.1% (3610/10000)
[Train] Epoch: 20.64 [6336/10000 (63%)]	Loss: 1.413268	Accuracy: 80.7 (5164/6400)
[Test]  Epoch: 21	Loss: 0.027316	Acc: 36.4% (3638/10000)
[Train] Epoch: 21.64 [6336/10000 (63%)]	Loss: 1.409153	Accuracy: 81.5 (5214/6400)
[Test]  Epoch: 22	Loss: 0.027688	Acc: 35.9% (3592/10000)
[Train] Epoch: 22.64 [6336/10000 (63%)]	Loss: 1.476546	Accuracy: 82.1 (5254/6400)
[Test]  Epoch: 23	Loss: 0.027419	Acc: 36.9% (3685/10000)
[Train] Epoch: 23.64 [6336/10000 (63%)]	Loss: 1.326682	Accuracy: 82.8 (5296/6400)
[Test]  Epoch: 24	Loss: 0.027303	Acc: 36.8% (3683/10000)
[Train] Epoch: 24.64 [6336/10000 (63%)]	Loss: 1.303066	Accuracy: 81.8 (5237/6400)
[Test]  Epoch: 25	Loss: 0.027336	Acc: 36.3% (3626/10000)
[Train] Epoch: 25.64 [6336/10000 (63%)]	Loss: 1.397911	Accuracy: 82.7 (5291/6400)
[Test]  Epoch: 26	Loss: 0.027119	Acc: 37.0% (3700/10000)
[Train] Epoch: 26.64 [6336/10000 (63%)]	Loss: 1.415828	Accuracy: 83.7 (5358/6400)
[Test]  Epoch: 27	Loss: 0.027169	Acc: 37.1% (3710/10000)
[Train] Epoch: 27.64 [6336/10000 (63%)]	Loss: 1.392842	Accuracy: 83.1 (5319/6400)
[Test]  Epoch: 28	Loss: 0.027186	Acc: 36.9% (3689/10000)
[Train] Epoch: 28.64 [6336/10000 (63%)]	Loss: 1.303991	Accuracy: 84.0 (5373/6400)
[Test]  Epoch: 29	Loss: 0.027529	Acc: 35.4% (3540/10000)
[Train] Epoch: 29.64 [6336/10000 (63%)]	Loss: 1.315670	Accuracy: 83.1 (5317/6400)
[Test]  Epoch: 30	Loss: 0.027518	Acc: 36.5% (3651/10000)
[Train] Epoch: 30.64 [6336/10000 (63%)]	Loss: 1.341737	Accuracy: 84.0 (5379/6400)
[Test]  Epoch: 31	Loss: 0.027781	Acc: 35.8% (3582/10000)
[Train] Epoch: 31.64 [6336/10000 (63%)]	Loss: 1.311689	Accuracy: 84.4 (5399/6400)
[Test]  Epoch: 32	Loss: 0.027184	Acc: 37.7% (3773/10000)
[Train] Epoch: 32.64 [6336/10000 (63%)]	Loss: 1.206463	Accuracy: 84.1 (5381/6400)
[Test]  Epoch: 33	Loss: 0.027313	Acc: 36.5% (3648/10000)
[Train] Epoch: 33.64 [6336/10000 (63%)]	Loss: 1.322135	Accuracy: 84.6 (5415/6400)
[Test]  Epoch: 34	Loss: 0.027885	Acc: 35.0% (3499/10000)
[Train] Epoch: 34.64 [6336/10000 (63%)]	Loss: 1.387156	Accuracy: 84.2 (5386/6400)
[Test]  Epoch: 35	Loss: 0.027329	Acc: 36.1% (3614/10000)
[Train] Epoch: 35.64 [6336/10000 (63%)]	Loss: 1.298622	Accuracy: 83.9 (5368/6400)
[Test]  Epoch: 36	Loss: 0.027453	Acc: 36.5% (3651/10000)
[Train] Epoch: 36.64 [6336/10000 (63%)]	Loss: 1.280502	Accuracy: 84.6 (5412/6400)
[Test]  Epoch: 37	Loss: 0.026969	Acc: 37.8% (3779/10000)
[Train] Epoch: 37.64 [6336/10000 (63%)]	Loss: 1.368857	Accuracy: 85.3 (5462/6400)
[Test]  Epoch: 38	Loss: 0.027100	Acc: 36.9% (3686/10000)
[Train] Epoch: 38.64 [6336/10000 (63%)]	Loss: 1.396515	Accuracy: 85.4 (5465/6400)
[Test]  Epoch: 39	Loss: 0.027028	Acc: 37.4% (3735/10000)
[Train] Epoch: 39.64 [6336/10000 (63%)]	Loss: 1.226337	Accuracy: 85.3 (5457/6400)
[Test]  Epoch: 40	Loss: 0.027071	Acc: 36.5% (3649/10000)
[Train] Epoch: 40.64 [6336/10000 (63%)]	Loss: 1.313272	Accuracy: 85.6 (5480/6400)
[Test]  Epoch: 41	Loss: 0.026986	Acc: 37.1% (3709/10000)
[Train] Epoch: 41.64 [6336/10000 (63%)]	Loss: 1.352731	Accuracy: 85.2 (5452/6400)
[Test]  Epoch: 42	Loss: 0.027017	Acc: 37.2% (3724/10000)
[Train] Epoch: 42.64 [6336/10000 (63%)]	Loss: 1.311993	Accuracy: 85.4 (5464/6400)
[Test]  Epoch: 43	Loss: 0.026879	Acc: 38.0% (3798/10000)
[Train] Epoch: 43.64 [6336/10000 (63%)]	Loss: 1.294314	Accuracy: 85.2 (5455/6400)
[Test]  Epoch: 44	Loss: 0.026974	Acc: 37.1% (3713/10000)
[Train] Epoch: 44.64 [6336/10000 (63%)]	Loss: 1.256290	Accuracy: 86.0 (5501/6400)
[Test]  Epoch: 45	Loss: 0.026826	Acc: 38.5% (3848/10000)
[Train] Epoch: 45.64 [6336/10000 (63%)]	Loss: 1.317791	Accuracy: 84.7 (5421/6400)
[Test]  Epoch: 46	Loss: 0.027097	Acc: 37.7% (3772/10000)
[Train] Epoch: 46.64 [6336/10000 (63%)]	Loss: 1.290612	Accuracy: 85.6 (5477/6400)
[Test]  Epoch: 47	Loss: 0.026911	Acc: 38.2% (3822/10000)
[Train] Epoch: 47.64 [6336/10000 (63%)]	Loss: 1.374602	Accuracy: 84.6 (5416/6400)
[Test]  Epoch: 48	Loss: 0.027428	Acc: 36.6% (3663/10000)
[Train] Epoch: 48.64 [6336/10000 (63%)]	Loss: 1.303062	Accuracy: 85.7 (5485/6400)
[Test]  Epoch: 49	Loss: 0.027239	Acc: 36.5% (3645/10000)
[Train] Epoch: 49.64 [6336/10000 (63%)]	Loss: 1.427805	Accuracy: 86.2 (5515/6400)
[Test]  Epoch: 50	Loss: 0.027197	Acc: 36.9% (3689/10000)
=> found transfer set with 10000 samples, 10 classes
Files already downloaded and verified

=> Training at budget = 10000
{'model_dir': 'models/adversary/cifar10-alexnet-adaptive-noise0.3-10000', 'model_arch': 'resnet34', 'testdataset': 'CIFAR10', 'budgets': '10000', 'device_id': 0, 'batch_size': 64, 'epochs': 50, 'lr': 0.01, 'momentum': 0.5, 'log_interval': 100, 'resume': None, 'lr_step': 60, 'lr_gamma': 0.1, 'num_workers': 10, 'pretrained': 'imagenet', 'img_obfs_tcq': 'noise', 'img_obfs_mag': 0.3, 'weighted_loss': False, 'argmaxed': False, 'optimizer_choice': 'sgdm'}
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[Train] Epoch: 0.64 [6336/10000 (63%)]	Loss: 1.824835	Accuracy: 30.8 (1971/6400)
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[Test]  Epoch: 1	Loss: 0.033554	Acc: 22.9% (2285/10000)
[Train] Epoch: 1.64 [6336/10000 (63%)]	Loss: 1.810252	Accuracy: 45.3 (2900/6400)
[Test]  Epoch: 2	Loss: 0.031308	Acc: 28.1% (2814/10000)
[Train] Epoch: 2.64 [6336/10000 (63%)]	Loss: 1.685780	Accuracy: 51.5 (3298/6400)
[Test]  Epoch: 3	Loss: 0.030451	Acc: 30.3% (3034/10000)
[Train] Epoch: 3.64 [6336/10000 (63%)]	Loss: 1.528291	Accuracy: 56.0 (3587/6400)
[Test]  Epoch: 4	Loss: 0.031454	Acc: 28.0% (2803/10000)
[Train] Epoch: 4.64 [6336/10000 (63%)]	Loss: 1.671474	Accuracy: 59.4 (3800/6400)
[Test]  Epoch: 5	Loss: 0.030420	Acc: 29.5% (2946/10000)
[Train] Epoch: 5.64 [6336/10000 (63%)]	Loss: 1.518212	Accuracy: 64.1 (4105/6400)
[Test]  Epoch: 6	Loss: 0.030310	Acc: 30.7% (3072/10000)
[Train] Epoch: 6.64 [6336/10000 (63%)]	Loss: 1.576998	Accuracy: 67.2 (4300/6400)
[Test]  Epoch: 7	Loss: 0.031038	Acc: 28.5% (2854/10000)
[Train] Epoch: 7.64 [6336/10000 (63%)]	Loss: 1.579474	Accuracy: 70.6 (4520/6400)
[Test]  Epoch: 8	Loss: 0.031224	Acc: 29.5% (2949/10000)
[Train] Epoch: 8.64 [6336/10000 (63%)]	Loss: 1.566131	Accuracy: 72.2 (4620/6400)
[Test]  Epoch: 9	Loss: 0.031080	Acc: 29.3% (2930/10000)
[Train] Epoch: 9.64 [6336/10000 (63%)]	Loss: 1.479706	Accuracy: 72.8 (4658/6400)
[Test]  Epoch: 10	Loss: 0.030640	Acc: 28.7% (2869/10000)
[Train] Epoch: 10.64 [6336/10000 (63%)]	Loss: 1.393474	Accuracy: 76.0 (4863/6400)
[Test]  Epoch: 11	Loss: 0.030941	Acc: 30.0% (2997/10000)
[Train] Epoch: 11.64 [6336/10000 (63%)]	Loss: 1.423203	Accuracy: 76.7 (4910/6400)
[Test]  Epoch: 12	Loss: 0.032434	Acc: 27.2% (2720/10000)
[Train] Epoch: 12.64 [6336/10000 (63%)]	Loss: 1.358793	Accuracy: 76.1 (4873/6400)
[Test]  Epoch: 13	Loss: 0.030959	Acc: 29.5% (2953/10000)
[Train] Epoch: 13.64 [6336/10000 (63%)]	Loss: 1.359566	Accuracy: 78.8 (5046/6400)
[Test]  Epoch: 14	Loss: 0.030453	Acc: 30.5% (3053/10000)
[Train] Epoch: 14.64 [6336/10000 (63%)]	Loss: 1.440551	Accuracy: 77.6 (4966/6400)
[Test]  Epoch: 15	Loss: 0.030964	Acc: 27.9% (2791/10000)
[Train] Epoch: 15.64 [6336/10000 (63%)]	Loss: 1.379787	Accuracy: 79.5 (5086/6400)
[Test]  Epoch: 16	Loss: 0.030250	Acc: 30.9% (3093/10000)
[Train] Epoch: 16.64 [6336/10000 (63%)]	Loss: 1.406646	Accuracy: 80.5 (5149/6400)
[Test]  Epoch: 17	Loss: 0.030534	Acc: 30.1% (3007/10000)
[Train] Epoch: 17.64 [6336/10000 (63%)]	Loss: 1.410862	Accuracy: 80.4 (5143/6400)
[Test]  Epoch: 18	Loss: 0.030355	Acc: 29.6% (2965/10000)
[Train] Epoch: 18.64 [6336/10000 (63%)]	Loss: 1.485113	Accuracy: 81.3 (5205/6400)
[Test]  Epoch: 19	Loss: 0.030888	Acc: 29.1% (2906/10000)
[Train] Epoch: 19.64 [6336/10000 (63%)]	Loss: 1.328984	Accuracy: 81.2 (5200/6400)
[Test]  Epoch: 20	Loss: 0.029807	Acc: 31.2% (3117/10000)
[Train] Epoch: 20.64 [6336/10000 (63%)]	Loss: 1.374595	Accuracy: 81.2 (5197/6400)
[Test]  Epoch: 21	Loss: 0.031439	Acc: 27.6% (2759/10000)
[Train] Epoch: 21.64 [6336/10000 (63%)]	Loss: 1.343436	Accuracy: 82.8 (5301/6400)
[Test]  Epoch: 22	Loss: 0.031251	Acc: 28.9% (2890/10000)
[Train] Epoch: 22.64 [6336/10000 (63%)]	Loss: 1.344367	Accuracy: 82.2 (5260/6400)
[Test]  Epoch: 23	Loss: 0.031189	Acc: 28.4% (2845/10000)
[Train] Epoch: 23.64 [6336/10000 (63%)]	Loss: 1.326846	Accuracy: 81.7 (5229/6400)
[Test]  Epoch: 24	Loss: 0.030099	Acc: 31.3% (3129/10000)
[Train] Epoch: 24.64 [6336/10000 (63%)]	Loss: 1.287895	Accuracy: 83.4 (5340/6400)
[Test]  Epoch: 25	Loss: 0.030153	Acc: 30.2% (3025/10000)
[Train] Epoch: 25.64 [6336/10000 (63%)]	Loss: 1.294691	Accuracy: 82.1 (5256/6400)
[Test]  Epoch: 26	Loss: 0.030688	Acc: 29.3% (2927/10000)
[Train] Epoch: 26.64 [6336/10000 (63%)]	Loss: 1.417961	Accuracy: 83.2 (5327/6400)
[Test]  Epoch: 27	Loss: 0.031142	Acc: 27.8% (2780/10000)
[Train] Epoch: 27.64 [6336/10000 (63%)]	Loss: 1.365675	Accuracy: 83.0 (5309/6400)
[Test]  Epoch: 28	Loss: 0.030787	Acc: 29.2% (2922/10000)
[Train] Epoch: 28.64 [6336/10000 (63%)]	Loss: 1.205164	Accuracy: 83.3 (5330/6400)
[Test]  Epoch: 29	Loss: 0.030340	Acc: 30.7% (3071/10000)
[Train] Epoch: 29.64 [6336/10000 (63%)]	Loss: 1.277154	Accuracy: 83.7 (5359/6400)
[Test]  Epoch: 30	Loss: 0.031115	Acc: 28.7% (2871/10000)
[Train] Epoch: 30.64 [6336/10000 (63%)]	Loss: 1.247834	Accuracy: 82.4 (5273/6400)
[Test]  Epoch: 31	Loss: 0.030626	Acc: 29.6% (2961/10000)
[Train] Epoch: 31.64 [6336/10000 (63%)]	Loss: 1.277402	Accuracy: 84.2 (5388/6400)
[Test]  Epoch: 32	Loss: 0.030410	Acc: 30.0% (3002/10000)
[Train] Epoch: 32.64 [6336/10000 (63%)]	Loss: 1.312492	Accuracy: 84.8 (5424/6400)
[Test]  Epoch: 33	Loss: 0.030689	Acc: 29.4% (2939/10000)
[Train] Epoch: 33.64 [6336/10000 (63%)]	Loss: 1.373126	Accuracy: 84.7 (5421/6400)
[Test]  Epoch: 34	Loss: 0.030859	Acc: 29.5% (2946/10000)
[Train] Epoch: 34.64 [6336/10000 (63%)]	Loss: 1.363740	Accuracy: 84.7 (5420/6400)
[Test]  Epoch: 35	Loss: 0.030617	Acc: 29.3% (2931/10000)
[Train] Epoch: 35.64 [6336/10000 (63%)]	Loss: 1.435821	Accuracy: 84.0 (5373/6400)
[Test]  Epoch: 36	Loss: 0.030740	Acc: 29.3% (2934/10000)
[Train] Epoch: 36.64 [6336/10000 (63%)]	Loss: 1.366831	Accuracy: 84.7 (5418/6400)
[Test]  Epoch: 37	Loss: 0.031456	Acc: 29.0% (2898/10000)
[Train] Epoch: 37.64 [6336/10000 (63%)]	Loss: 1.357256	Accuracy: 84.8 (5428/6400)
[Test]  Epoch: 38	Loss: 0.030274	Acc: 30.8% (3076/10000)
[Train] Epoch: 38.64 [6336/10000 (63%)]	Loss: 1.298484	Accuracy: 85.2 (5450/6400)
[Test]  Epoch: 39	Loss: 0.030511	Acc: 30.6% (3063/10000)
[Train] Epoch: 39.64 [6336/10000 (63%)]	Loss: 1.462171	Accuracy: 85.8 (5494/6400)
[Test]  Epoch: 40	Loss: 0.030395	Acc: 30.3% (3027/10000)
[Train] Epoch: 40.64 [6336/10000 (63%)]	Loss: 1.490515	Accuracy: 84.9 (5432/6400)
[Test]  Epoch: 41	Loss: 0.030147	Acc: 30.6% (3062/10000)
[Train] Epoch: 41.64 [6336/10000 (63%)]	Loss: 1.261331	Accuracy: 85.4 (5468/6400)
[Test]  Epoch: 42	Loss: 0.030303	Acc: 30.1% (3014/10000)
[Train] Epoch: 42.64 [6336/10000 (63%)]	Loss: 1.511468	Accuracy: 85.2 (5454/6400)
[Test]  Epoch: 43	Loss: 0.029886	Acc: 31.6% (3157/10000)
[Train] Epoch: 43.64 [6336/10000 (63%)]	Loss: 1.331665	Accuracy: 85.2 (5451/6400)
[Test]  Epoch: 44	Loss: 0.030807	Acc: 29.8% (2976/10000)
[Train] Epoch: 44.64 [6336/10000 (63%)]	Loss: 1.406287	Accuracy: 85.3 (5458/6400)
[Test]  Epoch: 45	Loss: 0.030034	Acc: 31.3% (3132/10000)
[Train] Epoch: 45.64 [6336/10000 (63%)]	Loss: 1.309011	Accuracy: 84.9 (5435/6400)
[Test]  Epoch: 46	Loss: 0.030425	Acc: 30.6% (3055/10000)
[Train] Epoch: 46.64 [6336/10000 (63%)]	Loss: 1.446696	Accuracy: 85.6 (5480/6400)
[Test]  Epoch: 47	Loss: 0.030326	Acc: 31.2% (3119/10000)
[Train] Epoch: 47.64 [6336/10000 (63%)]	Loss: 1.245177	Accuracy: 86.5 (5539/6400)
[Test]  Epoch: 48	Loss: 0.030484	Acc: 29.8% (2981/10000)
[Train] Epoch: 48.64 [6336/10000 (63%)]	Loss: 1.282807	Accuracy: 85.6 (5481/6400)
[Test]  Epoch: 49	Loss: 0.030590	Acc: 30.3% (3030/10000)
[Train] Epoch: 49.64 [6336/10000 (63%)]	Loss: 1.313976	Accuracy: 86.2 (5520/6400)
[Test]  Epoch: 50	Loss: 0.030539	Acc: 30.5% (3052/10000)
=> found transfer set with 10000 samples, 10 classes
Files already downloaded and verified

=> Training at budget = 10000
{'model_dir': 'models/adversary/cifar10-alexnet-adaptive-noise0.4-10000', 'model_arch': 'resnet34', 'testdataset': 'CIFAR10', 'budgets': '10000', 'device_id': 0, 'batch_size': 64, 'epochs': 50, 'lr': 0.01, 'momentum': 0.5, 'log_interval': 100, 'resume': None, 'lr_step': 60, 'lr_gamma': 0.1, 'num_workers': 10, 'pretrained': 'imagenet', 'img_obfs_tcq': 'noise', 'img_obfs_mag': 0.4, 'weighted_loss': False, 'argmaxed': False, 'optimizer_choice': 'sgdm'}
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[Train] Epoch: 0.64 [6336/10000 (63%)]	Loss: 1.942750	Accuracy: 30.3 (1941/6400)
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[Test]  Epoch: 1	Loss: 0.034013	Acc: 20.7% (2067/10000)
[Train] Epoch: 1.64 [6336/10000 (63%)]	Loss: 1.869999	Accuracy: 44.4 (2844/6400)
[Test]  Epoch: 2	Loss: 0.033306	Acc: 23.7% (2373/10000)
[Train] Epoch: 2.64 [6336/10000 (63%)]	Loss: 1.688286	Accuracy: 50.8 (3253/6400)
[Test]  Epoch: 3	Loss: 0.033453	Acc: 23.1% (2313/10000)
[Train] Epoch: 3.64 [6336/10000 (63%)]	Loss: 1.657065	Accuracy: 54.4 (3484/6400)
[Test]  Epoch: 4	Loss: 0.032681	Acc: 25.3% (2528/10000)
[Train] Epoch: 4.64 [6336/10000 (63%)]	Loss: 1.669694	Accuracy: 58.4 (3736/6400)
[Test]  Epoch: 5	Loss: 0.033605	Acc: 23.6% (2361/10000)
[Train] Epoch: 5.64 [6336/10000 (63%)]	Loss: 1.586036	Accuracy: 62.1 (3973/6400)
[Test]  Epoch: 6	Loss: 0.033476	Acc: 23.9% (2385/10000)
[Train] Epoch: 6.64 [6336/10000 (63%)]	Loss: 1.545102	Accuracy: 64.2 (4106/6400)
[Test]  Epoch: 7	Loss: 0.033588	Acc: 23.9% (2388/10000)
[Train] Epoch: 7.64 [6336/10000 (63%)]	Loss: 1.608346	Accuracy: 68.0 (4353/6400)
[Test]  Epoch: 8	Loss: 0.033932	Acc: 21.6% (2164/10000)
[Train] Epoch: 8.64 [6336/10000 (63%)]	Loss: 1.623035	Accuracy: 69.1 (4423/6400)
[Test]  Epoch: 9	Loss: 0.033900	Acc: 23.2% (2323/10000)
[Train] Epoch: 9.64 [6336/10000 (63%)]	Loss: 1.586494	Accuracy: 71.4 (4571/6400)
[Test]  Epoch: 10	Loss: 0.032613	Acc: 24.8% (2478/10000)
[Train] Epoch: 10.64 [6336/10000 (63%)]	Loss: 1.544303	Accuracy: 72.4 (4634/6400)
[Test]  Epoch: 11	Loss: 0.033126	Acc: 23.3% (2327/10000)
[Train] Epoch: 11.64 [6336/10000 (63%)]	Loss: 1.514392	Accuracy: 72.8 (4656/6400)
[Test]  Epoch: 12	Loss: 0.033348	Acc: 22.7% (2268/10000)
[Train] Epoch: 12.64 [6336/10000 (63%)]	Loss: 1.599627	Accuracy: 74.5 (4771/6400)
[Test]  Epoch: 13	Loss: 0.033645	Acc: 23.6% (2362/10000)
[Train] Epoch: 13.64 [6336/10000 (63%)]	Loss: 1.570738	Accuracy: 75.3 (4821/6400)
[Test]  Epoch: 14	Loss: 0.033771	Acc: 22.8% (2275/10000)
[Train] Epoch: 14.64 [6336/10000 (63%)]	Loss: 1.485811	Accuracy: 76.1 (4872/6400)
[Test]  Epoch: 15	Loss: 0.033484	Acc: 23.5% (2347/10000)
[Train] Epoch: 15.64 [6336/10000 (63%)]	Loss: 1.447785	Accuracy: 77.0 (4931/6400)
[Test]  Epoch: 16	Loss: 0.033455	Acc: 22.3% (2229/10000)
[Train] Epoch: 16.64 [6336/10000 (63%)]	Loss: 1.469360	Accuracy: 78.2 (5008/6400)
[Test]  Epoch: 17	Loss: 0.033697	Acc: 22.6% (2262/10000)
[Train] Epoch: 17.64 [6336/10000 (63%)]	Loss: 1.506657	Accuracy: 78.4 (5020/6400)
[Test]  Epoch: 18	Loss: 0.032655	Acc: 23.5% (2350/10000)
[Train] Epoch: 18.64 [6336/10000 (63%)]	Loss: 1.484979	Accuracy: 79.0 (5055/6400)
[Test]  Epoch: 19	Loss: 0.032632	Acc: 23.2% (2320/10000)
[Train] Epoch: 19.64 [6336/10000 (63%)]	Loss: 1.374430	Accuracy: 79.3 (5077/6400)
[Test]  Epoch: 20	Loss: 0.032387	Acc: 24.9% (2488/10000)
[Train] Epoch: 20.64 [6336/10000 (63%)]	Loss: 1.433066	Accuracy: 79.3 (5077/6400)
[Test]  Epoch: 21	Loss: 0.032605	Acc: 23.6% (2357/10000)
[Train] Epoch: 21.64 [6336/10000 (63%)]	Loss: 1.413721	Accuracy: 79.6 (5092/6400)
[Test]  Epoch: 22	Loss: 0.032458	Acc: 24.5% (2449/10000)
[Train] Epoch: 22.64 [6336/10000 (63%)]	Loss: 1.570273	Accuracy: 80.6 (5156/6400)
[Test]  Epoch: 23	Loss: 0.033298	Acc: 22.7% (2266/10000)
[Train] Epoch: 23.64 [6336/10000 (63%)]	Loss: 1.374241	Accuracy: 81.0 (5182/6400)
[Test]  Epoch: 24	Loss: 0.033543	Acc: 23.1% (2307/10000)
[Train] Epoch: 24.64 [6336/10000 (63%)]	Loss: 1.521810	Accuracy: 80.5 (5152/6400)
[Test]  Epoch: 25	Loss: 0.033530	Acc: 23.1% (2309/10000)
[Train] Epoch: 25.64 [6336/10000 (63%)]	Loss: 1.415566	Accuracy: 80.9 (5180/6400)
[Test]  Epoch: 26	Loss: 0.032698	Acc: 24.4% (2444/10000)
[Train] Epoch: 26.64 [6336/10000 (63%)]	Loss: 1.469358	Accuracy: 81.5 (5215/6400)
[Test]  Epoch: 27	Loss: 0.032451	Acc: 24.5% (2454/10000)
[Train] Epoch: 27.64 [6336/10000 (63%)]	Loss: 1.414378	Accuracy: 82.2 (5260/6400)
[Test]  Epoch: 28	Loss: 0.033167	Acc: 22.6% (2259/10000)
[Train] Epoch: 28.64 [6336/10000 (63%)]	Loss: 1.513530	Accuracy: 81.0 (5185/6400)
[Test]  Epoch: 29	Loss: 0.032977	Acc: 23.4% (2339/10000)
[Train] Epoch: 29.64 [6336/10000 (63%)]	Loss: 1.497990	Accuracy: 82.5 (5281/6400)
[Test]  Epoch: 30	Loss: 0.032991	Acc: 24.5% (2454/10000)
[Train] Epoch: 30.64 [6336/10000 (63%)]	Loss: 1.470872	Accuracy: 82.2 (5258/6400)
[Test]  Epoch: 31	Loss: 0.032975	Acc: 24.0% (2400/10000)
[Train] Epoch: 31.64 [6336/10000 (63%)]	Loss: 1.375429	Accuracy: 82.2 (5263/6400)
[Test]  Epoch: 32	Loss: 0.032902	Acc: 23.6% (2365/10000)
[Train] Epoch: 32.64 [6336/10000 (63%)]	Loss: 1.490854	Accuracy: 82.4 (5274/6400)
[Test]  Epoch: 33	Loss: 0.033162	Acc: 23.0% (2299/10000)
[Train] Epoch: 33.64 [6336/10000 (63%)]	Loss: 1.428691	Accuracy: 82.3 (5269/6400)
[Test]  Epoch: 34	Loss: 0.033119	Acc: 23.3% (2330/10000)
[Train] Epoch: 34.64 [6336/10000 (63%)]	Loss: 1.530369	Accuracy: 82.0 (5251/6400)
[Test]  Epoch: 35	Loss: 0.033597	Acc: 23.6% (2359/10000)
[Train] Epoch: 35.64 [6336/10000 (63%)]	Loss: 1.515910	Accuracy: 83.6 (5351/6400)
[Test]  Epoch: 36	Loss: 0.033420	Acc: 23.5% (2353/10000)
[Train] Epoch: 36.64 [6336/10000 (63%)]	Loss: 1.396940	Accuracy: 83.4 (5339/6400)
[Test]  Epoch: 37	Loss: 0.032609	Acc: 24.0% (2403/10000)
[Train] Epoch: 37.64 [6336/10000 (63%)]	Loss: 1.463720	Accuracy: 82.7 (5292/6400)
[Test]  Epoch: 38	Loss: 0.032539	Acc: 24.1% (2409/10000)
[Train] Epoch: 38.64 [6336/10000 (63%)]	Loss: 1.432363	Accuracy: 82.4 (5276/6400)
[Test]  Epoch: 39	Loss: 0.032518	Acc: 24.0% (2400/10000)
[Train] Epoch: 39.64 [6336/10000 (63%)]	Loss: 1.453004	Accuracy: 83.5 (5344/6400)
[Test]  Epoch: 40	Loss: 0.033125	Acc: 23.8% (2376/10000)
[Train] Epoch: 40.64 [6336/10000 (63%)]	Loss: 1.502126	Accuracy: 83.3 (5330/6400)
[Test]  Epoch: 41	Loss: 0.032901	Acc: 24.1% (2413/10000)
[Train] Epoch: 41.64 [6336/10000 (63%)]	Loss: 1.431145	Accuracy: 84.0 (5377/6400)
[Test]  Epoch: 42	Loss: 0.032843	Acc: 24.1% (2413/10000)
[Train] Epoch: 42.64 [6336/10000 (63%)]	Loss: 1.460730	Accuracy: 83.5 (5343/6400)
[Test]  Epoch: 43	Loss: 0.032949	Acc: 24.0% (2403/10000)
[Train] Epoch: 43.64 [6336/10000 (63%)]	Loss: 1.438454	Accuracy: 84.0 (5377/6400)
[Test]  Epoch: 44	Loss: 0.033009	Acc: 23.6% (2360/10000)
[Train] Epoch: 44.64 [6336/10000 (63%)]	Loss: 1.465338	Accuracy: 84.5 (5409/6400)
[Test]  Epoch: 45	Loss: 0.033567	Acc: 23.4% (2338/10000)
[Train] Epoch: 45.64 [6336/10000 (63%)]	Loss: 1.402010	Accuracy: 83.8 (5363/6400)
[Test]  Epoch: 46	Loss: 0.032790	Acc: 24.6% (2460/10000)
[Train] Epoch: 46.64 [6336/10000 (63%)]	Loss: 1.441009	Accuracy: 84.3 (5395/6400)
[Test]  Epoch: 47	Loss: 0.033396	Acc: 23.6% (2362/10000)
[Train] Epoch: 47.64 [6336/10000 (63%)]	Loss: 1.341501	Accuracy: 83.6 (5349/6400)
[Test]  Epoch: 48	Loss: 0.033150	Acc: 24.1% (2405/10000)
[Train] Epoch: 48.64 [6336/10000 (63%)]	Loss: 1.368271	Accuracy: 85.0 (5442/6400)
[Test]  Epoch: 49	Loss: 0.033448	Acc: 23.0% (2297/10000)
[Train] Epoch: 49.64 [6336/10000 (63%)]	Loss: 1.399371	Accuracy: 84.1 (5385/6400)
[Test]  Epoch: 50	Loss: 0.032760	Acc: 23.6% (2360/10000)
=> found transfer set with 10000 samples, 10 classes
Files already downloaded and verified

=> Training at budget = 10000
{'model_dir': 'models/adversary/cifar10-alexnet-adaptive-noise0.5-10000', 'model_arch': 'resnet34', 'testdataset': 'CIFAR10', 'budgets': '10000', 'device_id': 0, 'batch_size': 64, 'epochs': 50, 'lr': 0.01, 'momentum': 0.5, 'log_interval': 100, 'resume': None, 'lr_step': 60, 'lr_gamma': 0.1, 'num_workers': 10, 'pretrained': 'imagenet', 'img_obfs_tcq': 'noise', 'img_obfs_mag': 0.5, 'weighted_loss': False, 'argmaxed': False, 'optimizer_choice': 'sgdm'}
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[Train] Epoch: 0.64 [6336/10000 (63%)]	Loss: 2.062718	Accuracy: 27.1 (1732/6400)
/home/mohan235/jupyter_py3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
[Test]  Epoch: 1	Loss: 0.034614	Acc: 17.7% (1770/10000)
[Train] Epoch: 1.64 [6336/10000 (63%)]	Loss: 1.927480	Accuracy: 41.8 (2673/6400)
[Test]  Epoch: 2	Loss: 0.033391	Acc: 23.2% (2320/10000)
[Train] Epoch: 2.64 [6336/10000 (63%)]	Loss: 1.902896	Accuracy: 46.0 (2945/6400)
[Test]  Epoch: 3	Loss: 0.034083	Acc: 21.5% (2146/10000)
[Train] Epoch: 3.64 [6336/10000 (63%)]	Loss: 1.813568	Accuracy: 52.7 (3375/6400)
[Test]  Epoch: 4	Loss: 0.033814	Acc: 21.1% (2108/10000)
[Train] Epoch: 4.64 [6336/10000 (63%)]	Loss: 1.794482	Accuracy: 54.4 (3481/6400)
[Test]  Epoch: 5	Loss: 0.034043	Acc: 21.9% (2192/10000)
[Train] Epoch: 5.64 [6336/10000 (63%)]	Loss: 1.727872	Accuracy: 57.8 (3700/6400)
[Test]  Epoch: 6	Loss: 0.034372	Acc: 22.6% (2262/10000)
[Train] Epoch: 6.64 [6336/10000 (63%)]	Loss: 1.681277	Accuracy: 60.6 (3878/6400)
[Test]  Epoch: 7	Loss: 0.033870	Acc: 23.3% (2330/10000)
[Train] Epoch: 7.64 [6336/10000 (63%)]	Loss: 1.757658	Accuracy: 62.8 (4016/6400)
[Test]  Epoch: 8	Loss: 0.035072	Acc: 19.0% (1897/10000)
[Train] Epoch: 8.64 [6336/10000 (63%)]	Loss: 1.678787	Accuracy: 64.4 (4123/6400)
[Test]  Epoch: 9	Loss: 0.033869	Acc: 22.6% (2263/10000)
[Train] Epoch: 9.64 [6336/10000 (63%)]	Loss: 1.743884	Accuracy: 67.8 (4337/6400)
[Test]  Epoch: 10	Loss: 0.033917	Acc: 20.9% (2090/10000)
[Train] Epoch: 10.64 [6336/10000 (63%)]	Loss: 1.764969	Accuracy: 67.2 (4301/6400)
[Test]  Epoch: 11	Loss: 0.033749	Acc: 22.7% (2274/10000)
[Train] Epoch: 11.64 [6336/10000 (63%)]	Loss: 1.660390	Accuracy: 69.2 (4426/6400)
[Test]  Epoch: 12	Loss: 0.033973	Acc: 22.3% (2226/10000)
[Train] Epoch: 12.64 [6336/10000 (63%)]	Loss: 1.765168	Accuracy: 70.8 (4528/6400)
[Test]  Epoch: 13	Loss: 0.033491	Acc: 22.8% (2277/10000)
[Train] Epoch: 13.64 [6336/10000 (63%)]	Loss: 1.644614	Accuracy: 71.5 (4576/6400)
[Test]  Epoch: 14	Loss: 0.034070	Acc: 22.4% (2243/10000)
[Train] Epoch: 14.64 [6336/10000 (63%)]	Loss: 1.678458	Accuracy: 73.4 (4697/6400)
[Test]  Epoch: 15	Loss: 0.033689	Acc: 23.0% (2299/10000)
[Train] Epoch: 15.64 [6336/10000 (63%)]	Loss: 1.689079	Accuracy: 73.1 (4678/6400)
[Test]  Epoch: 16	Loss: 0.034022	Acc: 21.6% (2158/10000)
[Train] Epoch: 16.64 [6336/10000 (63%)]	Loss: 1.658191	Accuracy: 74.2 (4751/6400)
[Test]  Epoch: 17	Loss: 0.035002	Acc: 20.9% (2085/10000)
[Train] Epoch: 17.64 [6336/10000 (63%)]	Loss: 1.625602	Accuracy: 74.1 (4744/6400)
[Test]  Epoch: 18	Loss: 0.033849	Acc: 22.3% (2229/10000)
[Train] Epoch: 18.64 [6336/10000 (63%)]	Loss: 1.669658	Accuracy: 75.1 (4804/6400)
[Test]  Epoch: 19	Loss: 0.033196	Acc: 22.9% (2295/10000)
[Train] Epoch: 19.64 [6336/10000 (63%)]	Loss: 1.610403	Accuracy: 75.7 (4844/6400)
[Test]  Epoch: 20	Loss: 0.034013	Acc: 22.0% (2201/10000)
[Train] Epoch: 20.64 [6336/10000 (63%)]	Loss: 1.666985	Accuracy: 76.5 (4894/6400)
[Test]  Epoch: 21	Loss: 0.033257	Acc: 23.6% (2363/10000)
[Train] Epoch: 21.64 [6336/10000 (63%)]	Loss: 1.680098	Accuracy: 76.6 (4902/6400)
[Test]  Epoch: 22	Loss: 0.033884	Acc: 22.4% (2245/10000)
[Train] Epoch: 22.64 [6336/10000 (63%)]	Loss: 1.665163	Accuracy: 78.2 (5002/6400)
[Test]  Epoch: 23	Loss: 0.033756	Acc: 23.2% (2325/10000)
[Train] Epoch: 23.64 [6336/10000 (63%)]	Loss: 1.587573	Accuracy: 77.3 (4949/6400)
[Test]  Epoch: 24	Loss: 0.033255	Acc: 23.7% (2371/10000)
[Train] Epoch: 24.64 [6336/10000 (63%)]	Loss: 1.643576	Accuracy: 77.3 (4950/6400)
[Test]  Epoch: 25	Loss: 0.033537	Acc: 22.5% (2246/10000)
[Train] Epoch: 25.64 [6336/10000 (63%)]	Loss: 1.611299	Accuracy: 78.1 (5000/6400)
[Test]  Epoch: 26	Loss: 0.033750	Acc: 22.7% (2270/10000)
[Train] Epoch: 26.64 [6336/10000 (63%)]	Loss: 1.705033	Accuracy: 79.5 (5086/6400)
[Test]  Epoch: 27	Loss: 0.033835	Acc: 21.6% (2162/10000)
[Train] Epoch: 27.64 [6336/10000 (63%)]	Loss: 1.642002	Accuracy: 78.8 (5042/6400)
[Test]  Epoch: 28	Loss: 0.034406	Acc: 21.5% (2154/10000)
[Train] Epoch: 28.64 [6336/10000 (63%)]	Loss: 1.629346	Accuracy: 79.0 (5054/6400)
[Test]  Epoch: 29	Loss: 0.033202	Acc: 23.5% (2348/10000)
[Train] Epoch: 29.64 [6336/10000 (63%)]	Loss: 1.621746	Accuracy: 79.6 (5097/6400)
[Test]  Epoch: 30	Loss: 0.032869	Acc: 23.5% (2348/10000)
[Train] Epoch: 30.64 [6336/10000 (63%)]	Loss: 1.607648	Accuracy: 78.9 (5052/6400)
[Test]  Epoch: 31	Loss: 0.033277	Acc: 23.9% (2390/10000)
[Train] Epoch: 31.64 [6336/10000 (63%)]	Loss: 1.589634	Accuracy: 79.4 (5082/6400)
[Test]  Epoch: 32	Loss: 0.033784	Acc: 21.6% (2163/10000)
[Train] Epoch: 32.64 [6336/10000 (63%)]	Loss: 1.588379	Accuracy: 80.3 (5140/6400)
[Test]  Epoch: 33	Loss: 0.033522	Acc: 22.0% (2204/10000)
[Train] Epoch: 33.64 [6336/10000 (63%)]	Loss: 1.644076	Accuracy: 80.0 (5117/6400)
[Test]  Epoch: 34	Loss: 0.034424	Acc: 21.9% (2186/10000)
[Train] Epoch: 34.64 [6336/10000 (63%)]	Loss: 1.637882	Accuracy: 80.2 (5133/6400)
[Test]  Epoch: 35	Loss: 0.033089	Acc: 23.2% (2323/10000)
[Train] Epoch: 35.64 [6336/10000 (63%)]	Loss: 1.617101	Accuracy: 80.8 (5173/6400)
[Test]  Epoch: 36	Loss: 0.033410	Acc: 22.3% (2232/10000)
[Train] Epoch: 36.64 [6336/10000 (63%)]	Loss: 1.559584	Accuracy: 81.2 (5197/6400)
[Test]  Epoch: 37	Loss: 0.033575	Acc: 22.7% (2269/10000)
[Train] Epoch: 37.64 [6336/10000 (63%)]	Loss: 1.688638	Accuracy: 80.8 (5173/6400)
[Test]  Epoch: 38	Loss: 0.033380	Acc: 22.5% (2252/10000)
[Train] Epoch: 38.64 [6336/10000 (63%)]	Loss: 1.558892	Accuracy: 81.0 (5187/6400)
[Test]  Epoch: 39	Loss: 0.033037	Acc: 23.0% (2304/10000)
[Train] Epoch: 39.64 [6336/10000 (63%)]	Loss: 1.625511	Accuracy: 81.4 (5207/6400)
[Test]  Epoch: 40	Loss: 0.033628	Acc: 22.8% (2278/10000)
[Train] Epoch: 40.64 [6336/10000 (63%)]	Loss: 1.624665	Accuracy: 81.5 (5219/6400)
[Test]  Epoch: 41	Loss: 0.034786	Acc: 22.0% (2203/10000)
[Train] Epoch: 41.64 [6336/10000 (63%)]	Loss: 1.563906	Accuracy: 81.2 (5195/6400)
[Test]  Epoch: 42	Loss: 0.033529	Acc: 22.3% (2230/10000)
[Train] Epoch: 42.64 [6336/10000 (63%)]	Loss: 1.602121	Accuracy: 80.9 (5178/6400)
[Test]  Epoch: 43	Loss: 0.033710	Acc: 22.1% (2214/10000)
[Train] Epoch: 43.64 [6336/10000 (63%)]	Loss: 1.566953	Accuracy: 80.7 (5162/6400)
[Test]  Epoch: 44	Loss: 0.033926	Acc: 22.3% (2234/10000)
[Train] Epoch: 44.64 [6336/10000 (63%)]	Loss: 1.578667	Accuracy: 81.4 (5209/6400)
[Test]  Epoch: 45	Loss: 0.033695	Acc: 22.4% (2243/10000)
[Train] Epoch: 45.64 [6336/10000 (63%)]	Loss: 1.568382	Accuracy: 81.6 (5220/6400)
[Test]  Epoch: 46	Loss: 0.033276	Acc: 23.6% (2358/10000)
[Train] Epoch: 46.64 [6336/10000 (63%)]	Loss: 1.561024	Accuracy: 82.4 (5272/6400)
[Test]  Epoch: 47	Loss: 0.033579	Acc: 22.0% (2201/10000)
[Train] Epoch: 47.64 [6336/10000 (63%)]	Loss: 1.619503	Accuracy: 82.4 (5274/6400)
[Test]  Epoch: 48	Loss: 0.034296	Acc: 22.6% (2257/10000)
[Train] Epoch: 48.64 [6336/10000 (63%)]	Loss: 1.583165	Accuracy: 82.9 (5305/6400)
[Test]  Epoch: 49	Loss: 0.033500	Acc: 23.5% (2350/10000)
[Train] Epoch: 49.64 [6336/10000 (63%)]	Loss: 1.617073	Accuracy: 82.6 (5284/6400)
[Test]  Epoch: 50	Loss: 0.034246	Acc: 22.2% (2220/10000)
